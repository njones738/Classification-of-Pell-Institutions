{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from joblib import Memory\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.special import expit\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "from copy import copy\n",
    "from sklearn import svm\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as p9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rand_state = 5991"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def split_data(xx, yy, testsize = 1000):\n",
    "    xtrain, xtest, y_train, y_test = train_test_split(xx,\n",
    "                                                      yy,\n",
    "                                                      test_size = testsize,\n",
    "                                                      random_state = rand_state)\n",
    "    xtrain, xvalid, y_train, y_valid = train_test_split(xtrain, y_train, \n",
    "                                                        test_size = testsize,\n",
    "                                                        random_state = rand_state)\n",
    "    y_train = np.array(y_train).reshape(-1, 1)\n",
    "    y_test = np.array(y_test).reshape(-1, 1)\n",
    "    y_valid = np.array(y_valid).reshape(-1, 1)\n",
    "\n",
    "    print(\" SHAPE of xtrain:\", xtrain.shape)\n",
    "    print(\"SHAPE of y_train:\", y_train.shape)\n",
    "    print(\"  SHAPE of xtest:\", xtest.shape)\n",
    "    print(\" SHAPE of y_test:\", y_test.shape)\n",
    "    print(\" SHAPE of xvalid:\", xvalid.shape)\n",
    "    print(\"SHAPE of y_valid:\", y_valid.shape)\n",
    "\n",
    "    return xtrain, y_train, xtest, y_test, xvalid, y_valid \n",
    "\n",
    "def get_acc_auc(y, p):\n",
    "    acc = np.sum(y == p) / len(y)\n",
    "    auc = roc_auc_score(y, p)\n",
    "    return acc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "idcsc = \"postprocess/idcsc.feather\"\n",
    "cipcsc = \"postprocess/cipcsc.feather\"\n",
    "geoloccsc = \"postprocess/geoloccsc.feather\"\n",
    "instdemocsc = \"postprocess/instdemocsc.feather\"\n",
    "studdemocsc = \"postprocess/studdemocsc.feather\"\n",
    "pcipcsc = \"postprocess/pcipcsc.feather\"\n",
    "numcsc = \"postprocess/numcsc.feather\"\n",
    "tarcsc = \"postprocess/tarcsc.feather\"\n",
    "fulldf = \"postprocess/fulldf.feather\"\n",
    "\n",
    "num_only = pd.read_csv(\"C:/Code/GITHUB/csc/Classification-of-Pell-Institutions/numeric_only.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_csc = feather.read_feather(idcsc)\n",
    "cip_csc = feather.read_feather(cipcsc)\n",
    "geolocation_csc = feather.read_feather(geoloccsc)\n",
    "inst_demographic_csc = feather.read_feather(instdemocsc)\n",
    "stud_demographic_csc = feather.read_feather(studdemocsc)\n",
    "pcip_csc = feather.read_feather(pcipcsc)\n",
    "num_csc = feather.read_feather(numcsc)\n",
    "tar_csc = feather.read_feather(tarcsc)\n",
    "\n",
    "full_df = feather.read_feather(fulldf)\n",
    "\n",
    "missing = pd.DataFrame(full_df.isna().sum())\n",
    "missing.reset_index(inplace=True)\n",
    "missing[missing[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the ids column in the target frame match the the ids column in the full frame for each unique UNITID?\n",
    "df = pd.merge(tar_csc[[\"ids\", \"UNITID\"]],\n",
    "         full_df[[\"ids\", \"UNITID\", \"INSTNM\"]],\n",
    "         how = \"left\", left_on = \"UNITID\", right_on = \"UNITID\",\n",
    "         suffixes=(\"_target\", \"_full\"))\n",
    "df[\"diff\"] = df[\"ids_target\"] - df[\"ids_full\"]\n",
    "df.loc[df[\"diff\"] > 0 ]\n",
    "# Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Majority Pell to have the value of 1 and Minority Pell to have the value of 0.\n",
    "# check before\n",
    "df = pd.merge(id_csc, tar_csc, how = \"left\",\n",
    "              left_on = \"UNITID\", right_on = \"UNITID\",\n",
    "              suffixes = [\"_id\", \"_target\"])\n",
    "df[[\"PELLCAT_id\", \"PCTPELL\", \"PELLCAT_target\"]]\n",
    "\n",
    "pc_dict = { 1: \"MINPELL\", 0: \"MAJPELL\" } # originally Minority Pell equals 1, and Majority Pell equals 0.\n",
    "pc_dict2 = { \"MINPELL\": 0, \"MAJPELL\": 1 } # I want to change Minority Pell to equal 0 and Majority Pell to equal 1.\n",
    "tar_csc[\"PELLCAT\"] = tar_csc[\"PELLCAT\"].map(pc_dict)\n",
    "tar_csc[\"PELLCAT\"] = tar_csc[\"PELLCAT\"].map(pc_dict2)\n",
    "id_csc[\"PELLCAT\"] = id_csc[\"PELLCAT\"].map(pc_dict)\n",
    "id_csc[\"PELLCAT\"] = id_csc[\"PELLCAT\"].map(pc_dict2)\n",
    "\n",
    "# check after\n",
    "df = pd.merge(id_csc, tar_csc, how = \"left\",\n",
    "              left_on = \"UNITID\", right_on = \"UNITID\",\n",
    "              suffixes = [\"_id\", \"_target\"])\n",
    "df[[\"PELLCAT_id\", \"PCTPELL\", \"PELLCAT_target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tar_csc[\"PELLCAT\"].copy()\n",
    "xs = full_df.drop([\"ids\", \"UNITID\"], axis = 1).copy()\n",
    "print(\"SHAPE of xs:\", xs.shape)\n",
    "print(\"SHAPE of ys:\", ys.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, y_train, xtest, y_test, xvalid, y_valid = split_data(xs, ys, testsize = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for non-linear associations between individual features and the binary target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain.shape)\n",
    "\n",
    "xnot = list(xtrain.columns[xtrain.columns.str.endswith(\"ASSOC\") | xtrain.columns.str.endswith(\"BACHL\") |\n",
    "                      xtrain.columns.str.endswith(\"CERT1\") | xtrain.columns.str.endswith(\"CERT2\") |\n",
    "                      xtrain.columns.str.endswith(\"CERT4\")])\n",
    "xnot2 = [\"INSTNM\", \"ACCREDAGENCY\", \"ACCREDCODE\", \"CITY\", \"Season\", \"STABBR\", \"T4APPROVALDATE\", \"ZIP\"]\n",
    "xnot.extend(xnot2)\n",
    "\n",
    "print(\"variables to be removed:\")\n",
    "print(len(xnot))\n",
    "print(\"remaining variables:\")\n",
    "\n",
    "features = xtrain.columns.drop(xnot)\n",
    "\n",
    "print(len(features))\n",
    "\n",
    "missing = pd.DataFrame(xtrain[features].isna().sum())\n",
    "missing.reset_index(inplace=True)\n",
    "missing[missing[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "poly = PolynomialFeatures(3)\n",
    "\n",
    "scaler.fit(xtrain[features])\n",
    "xtrain = pd.DataFrame(scaler.transform(xtrain[features]), columns = features)\n",
    "xvalid = pd.DataFrame(scaler.transform(xvalid[features]), columns = features)\n",
    "xtest = pd.DataFrame(scaler.transform(xtest[features]), columns = features)\n",
    "\n",
    "log_reg = LogisticRegression(solver = 'saga',\n",
    "                             random_state = rand_state,\n",
    "                             penalty = 'l1',\n",
    "                             class_weight = 'balanced',\n",
    "                             max_iter = 1000)\n",
    "\n",
    "print(\"xtrain before: \", xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDIT: Dr. Vanderheyden wrote this code.\n",
    "accuracies = []\n",
    "for f in features:\n",
    "\n",
    "    x = xtrain[f].values.reshape(-1, 1)\n",
    "    y = y_train.reshape(-1, 1)\n",
    "    ## LIN ##############################\n",
    "    log_reg.fit(x, y)\n",
    "    acc, auc = get_acc_auc(y, log_reg.predict(x))\n",
    "    ## LOG #############################   \n",
    "    xl = np.log(x - np.min(x) + 1)\n",
    "    log_reg.fit(xl, y)\n",
    "    lcc, luc = get_acc_auc(y, log_reg.predict(xl))\n",
    "    if lcc / acc >= 1.1 or luc / auc >= 1.05:  # if bin accuracy is 110% of linear accuracy or ... AUC is 105% ...\n",
    "        xtrain[f + ' log'] = xl\n",
    "        xvalid[f + ' log'] = np.log(xvalid[f].values.reshape(-1, 1) - np.min(xtrain[f])+1)\n",
    "        xtest[f + ' log'] = np.log(xtest[f].values.reshape(-1, 1) - np.min(xtrain[f])+1)\n",
    "    ## EXP #############################   \n",
    "    xe = np.exp(x)\n",
    "    log_reg.fit(xe, y)\n",
    "    ecc, euc = get_acc_auc(y, log_reg.predict(xe))\n",
    "    if ecc / acc >= 1.1 or euc / auc >= 1.05: \n",
    "        xtrain[f + ' exp'] = xe\n",
    "        xvalid[f + ' exp'] = np.exp(xvalid[f].values.reshape(-1, 1))\n",
    "        xtest[f + ' exp'] = np.exp(xtest[f].values.reshape(-1, 1))\n",
    "    ## POLY ############################# \n",
    "    poly.fit(x)\n",
    "    xp = poly.transform(x)\n",
    "    log_reg.fit(xp, y)\n",
    "    pcc, puc = get_acc_auc(y, log_reg.predict(xp))\n",
    "    if pcc / acc >= 1.1 or puc / auc >= 1.05:  # if bin accuracy is 110% of linear accuracy or ... AUC is 105% ...\n",
    "        xtrain[f + ' p2'] = x**2\n",
    "        xtrain[f + ' p3'] = x**3\n",
    "        xvalid[f + ' p2'] = (xvalid[f].values)**2\n",
    "        xvalid[f + ' p3'] = (xvalid[f].values)**3\n",
    "        xtest[f + ' p2'] = (xtest[f].values)**2\n",
    "        xtest[f + ' p3'] = (xtest[f].values)**3\n",
    "    ## BIN #############################\n",
    "    xmin = x.min()\n",
    "    rnge = x.max() - xmin\n",
    "    xtrn = 0 + ((x - xmin) > 1 * rnge / 10) + ((x - xmin) > 2 * rnge / 10) + ((x - xmin) > 3 * rnge / 10) + ( # the objects in each\n",
    "                (x - xmin) > 4 * rnge / 10) + ((x - xmin) > 5 * rnge / 10) + ((x - xmin) > 6 * rnge / 10) + ( # bracket returns true\n",
    "                (x - xmin) > 7 * rnge / 10) + ((x - xmin) > 8 * rnge / 10) + ((x - xmin) > 9 * rnge / 10)     # or false \n",
    "    xval = 0 + ((xvalid[f] - xmin) > 1 * rnge / 10) + ((xvalid[f] - xmin) > 2 * rnge / 10) + ((xvalid[f] - xmin) > 3 * rnge / 10) + (\n",
    "                (xvalid[f] - xmin) > 4 * rnge / 10) + ((xvalid[f] - xmin) > 5 * rnge / 10) + ((xvalid[f] - xmin) > 6 * rnge / 10) + (\n",
    "                (xvalid[f] - xmin) > 7 * rnge / 10) + ((xvalid[f] - xmin) > 8 * rnge / 10) + ((xvalid[f] - xmin) > 9 * rnge / 10)\n",
    "    xtst = 0 + ((xtest[f] - xmin) > 1 * rnge / 10) + ((xtest[f] - xmin) > 2 * rnge / 10) + ((xtest[f] - xmin) > 5 * rnge / 10) + (\n",
    "                (xtest[f] - xmin) > 3 * rnge / 10) + ((xtest[f] - xmin) > 4 * rnge / 10) + ((xtest[f] - xmin) > 6 * rnge / 10) + (\n",
    "                (xtest[f] - xmin) > 7 * rnge / 10) + ((xtest[f] - xmin) > 8 * rnge / 10) + ((xtest[f] - xmin) > 9 * rnge / 10)\n",
    "    encoder = TargetEncoder()\n",
    "    encoder.fit(xtrn, y)\n",
    "    xb = encoder.transform(xtrn)\n",
    "    log_reg.fit(xb, y)\n",
    "    bcc, buc = get_acc_auc(y, log_reg.predict(xb))\n",
    "    if bcc / acc >= 1.1 or buc / auc >= 1.05: # if bin accuracy is 110% of linear accuracy or ... AUC is 105% ...\n",
    "        xtrain[f + ' Bin'] = xb\n",
    "        xvalid[f + ' Bin'] = encoder.transform(xval)\n",
    "        xtest[f + ' Bin'] = encoder.transform(xtst)\n",
    "    ## COMPLETION #############################\n",
    "    lDa = lcc / acc\n",
    "    eDa = ecc / acc\n",
    "    pDa = pcc / acc\n",
    "    bDa = bcc / acc\n",
    "    lda = luc / auc\n",
    "    eda = euc / auc\n",
    "    pda = puc / auc\n",
    "    bda = buc / auc\n",
    "    accuracies.append([f, acc, lcc, ecc, pcc, bcc, auc, luc, euc, puc, buc, lDa, eDa, pDa, bDa, lda, eda, pda, bda])\n",
    "###############################################\n",
    "\n",
    "colums = ['Feature','ACC: Linear', 'ACC: Log', 'ACC: Exp', 'ACC: Poly3','ACC: Bin',\n",
    "                    'AUC: Simple Linear', 'AUC: Log', 'AUC: Exp','AUC: Poly3', 'AUC: Bin',\n",
    "                    \"ACC: LOG / Linear\", \"ACC: EXP / Linear\", \"ACC: Poly3 / Linear\", \"ACC: Bin / Linear\",\n",
    "                    \"AUC: LOG / Linear\", \"AUC: EXP / Linear\", \"AUC: Poly3 / Linear\", \"AUC: Bin / Linear\"]\n",
    "accDf = pd.DataFrame(accuracies, columns = colums)\n",
    "accDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain.shape)\n",
    "accDf.head(5)\n",
    "accDf.loc[:, [\"ACC: LOG / Linear\", \"ACC: EXP / Linear\", \"ACC: Poly3 / Linear\", \"ACC: Bin / Linear\",\n",
    "           \"AUC: LOG / Linear\", \"AUC: EXP / Linear\", \"AUC: Poly3 / Linear\", \"AUC: Bin / Linear\"]].sort_values(\"ACC: LOG / Linear\", ascending = False).head(5)\n",
    "# accDf.sort_values(\"AUC: Log\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Correlation of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "corrs = []\n",
    "contFeat = list(xtrain.columns)\n",
    "contFeat_length = len(contFeat)\n",
    "\n",
    "\n",
    "for i in range(contFeat_length):\n",
    "    for j in range(i + 1, contFeat_length):\n",
    "        feati = xtrain[contFeat[i]].values.flatten()\n",
    "        featj = xtrain[contFeat[j]].values.flatten()\n",
    "\n",
    "        corr, _ = pearsonr(feati, featj)\n",
    "        corrs.append([feati, featj, corr, contFeat[i], contFeat[j]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correl = pd.DataFrame(corrs, columns = ['f1', 'f2', 'P Corr', \"feat1\", \"feat2\"])\n",
    "################################\n",
    "num_var_g50 = len(correl[abs(correl['P Corr']) > 0.5])\n",
    "pct_var_g50 = num_var_g50 / (contFeat_length * (contFeat_length - 1) / 2)\n",
    "print(xtrain.shape)\n",
    "print('Total number of features pairs: )', num_var_g50)\n",
    "print('Number of features pairs with absolute Pearson Correl above 0.5: )', num_var_g50)\n",
    "print('Percent of features pairs with absolute Pearson Correl above 0.5: )', pct_var_g50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_var_g50 * 100\n",
    "correl[abs(correl['P Corr']) > 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "log = LogisticRegression(solver = 'saga',\n",
    "                         random_state = rand_state, \n",
    "                         penalty = 'l1', \n",
    "                         C = 0.05, \n",
    "                         class_weight = 'balanced',\n",
    "                         max_iter = 3000)\n",
    "log.fit(xtrain, y_train)\n",
    "\n",
    "Tprob = log.predict_proba(xtrain)\n",
    "vprob = log.predict_proba(xvalid)\n",
    "tprob = log.predict_proba(xtest)\n",
    "\n",
    "print('Train AUC and Accuracy: ', roc_auc_score(y_train, Tprob[:,1]), 1 - np.mean(abs(y_train - log.predict(xtrain))))\n",
    "print('Train AUC and Accuracy: ', roc_auc_score(y_test, tprob[:,1]), 1 - np.mean(abs(y_test - log.predict(xvalid))))\n",
    "print('Val AUC and Accuracy: ', roc_auc_score(y_valid, vprob[:,1]), 1 - np.mean(abs(y_valid - log.predict(xtest))))\n",
    "print('Number of Weights equal to zero: ', np.sum(log.coef_==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "leafs = [2, 5, 10, 20, 30, 40]\n",
    "depths = [5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "for l in leafs:\n",
    "    for d in depths:\n",
    "        forest = RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=d, min_samples_leaf=l, class_weight='balanced_subsample', random_state = 67)\n",
    "\n",
    "        forest.fit(xtrain, y_train)\n",
    "\n",
    "        Tpred = forest.predict(xtrain)\n",
    "        vpred = forest.predict(xval)\n",
    "\n",
    "        Tprob = forest.predict_proba(xtrain)\n",
    "        vprob = forest.predict_proba(xval)\n",
    "        tprob = forest.predict_proba(xtest)\n",
    "\n",
    "        print('Train AUC and Accuracy: ', l, d, roc_auc_score(y_train, Tprob[:,1]), 1 - np.mean(abs(y_train - Tpred)))\n",
    "        print('Val AUC and Accuracy: ', l, d, roc_auc_score(y_val, vprob[:,1]), 1 - np.mean(abs(y_val- vpred)))\n",
    "        print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "591957650fd2dfa38b1c766d9610be12ab5ecbc623c9062aec785c096eff7328"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
