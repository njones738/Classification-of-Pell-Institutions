{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from copy import copy\n",
    "from pathlib import Path\n",
    "from joblib import Memory\n",
    "from scipy import sparse\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.special import expit\n",
    "from scipy.stats import pearsonr\n",
    "import scikitplot as skplt\n",
    "import shap\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder, normalize\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "import pyarrow.feather as feather\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as p9\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "rand_state = 5991\n",
    "\n",
    "# Paths\n",
    "idcsc = \"C:/Code/GITHUB/csc/Classification-of-Pell-Institutions/scripts/here_we_are/id_csc.feather\"\n",
    "tarcsc = \"C:/Code/GITHUB/csc/Classification-of-Pell-Institutions/scripts/here_we_are/tarcsc.feather\"\n",
    "fulldf = \"C:/Code/GITHUB/csc/Classification-of-Pell-Institutions/scripts/here_we_are/full_df.feather\"\n",
    "\n",
    "my_filesys_pth = \"C:/Code/GITHUB/csc/Classification-of-Pell-Institutions/\"\n",
    "\n",
    "# REGRESSION PROJECT IS ASKING THE QUESTION: \n",
    "#       Can I predict the number of students \n",
    "#           that are receiving a Pell grant \n",
    "#           from the student demographic \n",
    "#           profile of an institution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "def split_data(xx, yy, testsize = 1000):\n",
    "    xtrain, xtest, y_train, y_test = train_test_split(xx,\n",
    "                                                      yy,\n",
    "                                                      test_size = testsize,\n",
    "                                                      random_state = rand_state)\n",
    "    xtrain, xvalid, y_train, y_valid = train_test_split(xtrain, y_train, \n",
    "                                                        test_size = testsize,\n",
    "                                                        random_state = rand_state)\n",
    "    y_train = np.array(y_train).reshape(-1, 1)\n",
    "    y_test = np.array(y_test).reshape(-1, 1)\n",
    "    y_valid = np.array(y_valid).reshape(-1, 1)\n",
    "\n",
    "    print(\" SHAPE of xtrain:\", xtrain.shape)\n",
    "    print(\"SHAPE of y_train:\", y_train.shape)\n",
    "    print(\"  SHAPE of xtest:\", xtest.shape)\n",
    "    print(\" SHAPE of y_test:\", y_test.shape)\n",
    "    print(\" SHAPE of xvalid:\", xvalid.shape)\n",
    "    print(\"SHAPE of y_valid:\", y_valid.shape)\n",
    "\n",
    "    return xtrain, y_train, xtest, y_test, xvalid, y_valid \n",
    "\n",
    "def get_acc_auc(y, p):\n",
    "    acc = np.sum(y == p) / len(y)\n",
    "    auc = roc_auc_score(y, p)\n",
    "    return acc, auc\n",
    "\n",
    "def get_outs(model, train, test, valid, ytrain, ytest, yvalid):\n",
    "    train_acc = round(model.score(train, ytrain), 4)\n",
    "    test_acc = round(model.score(test, ytest), 4)\n",
    "    valid_acc = round(model.score(valid, yvalid), 4)\n",
    "\n",
    "    train_auc = round(roc_auc_score(ytrain, model.predict_proba(train)[:,1]), 4)\n",
    "    test_auc = round(roc_auc_score(ytest, model.predict_proba(test)[:,1]), 4)\n",
    "    valid_auc = round(roc_auc_score(yvalid, model.predict_proba(valid)[:,1]), 4)\n",
    "\n",
    "    return train_auc, test_auc, valid_auc, train_acc, test_acc, valid_acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_csc = feather.read_feather(idcsc)\n",
    "tar_csc = feather.read_feather(tarcsc)\n",
    "full_df = feather.read_feather(fulldf)\n",
    "\n",
    "missing = pd.DataFrame(full_df.isna().sum())\n",
    "missing.reset_index(inplace=True)\n",
    "missing[missing[0] > 0]\n",
    "\n",
    "# Do the ids column in the target frame match the the ids column in the full frame for each unique UNITID?\n",
    "# df = pd.merge(tar_csc[[\"ids\", \"UNITID\"]],\n",
    "#          full_df[[\"ids\", \"UNITID\"]],\n",
    "#          how = \"left\", left_on = \"UNITID\", right_on = \"UNITID\",\n",
    "#          suffixes=(\"_target\", \"_full\"))\n",
    "# df[\"diff\"] = df[\"ids_target\"] - df[\"ids_full\"]\n",
    "# df.loc[df[\"diff\"] > 0 ]\n",
    "# # Yes\n",
    "# tar_csc[\"PELLCAT\"] = abs(1 - tar_csc[\"PELLCAT\"])\n",
    "\n",
    "\n",
    "tar_csc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# dffff = full_df.drop([\"ids\", \"UNITID\", \"FTFTPCTPELL\", \"ST_FIPS\", \"LOCALE_31\"], axis = 1)\n",
    "# print(dffff.shape)\n",
    "\n",
    "# select = VarianceThreshold(threshold = 0.21)\n",
    "# select.fit(dffff)\n",
    "# const_columns = [column for column in dffff.columns if column not in dffff.columns[select.get_support()]]\n",
    "# print(len(const_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = tar_csc[\"PELLCAT\"].copy()\n",
    "full_df[\"ST_FIPS\"] = full_df[\"ST_FIPS\"].astype(int)\n",
    "xs = full_df.drop([\"ids\", \"UNITID\", \"FTFTPCTPELL\", \"ST_FIPS\", \"LOCALE_31\", \"LPPPLUS_AMT\", \"LPSTAFFORD_CNT\"], axis = 1).copy()\n",
    "print(\"SHAPE of xs:\", xs.shape)\n",
    "print(\"SHAPE of ys:\", ys.shape)\n",
    "xtrain, y_train, xtest, y_test, xvalid, y_valid = split_data(xs, ys, testsize = 1000)\n",
    "print(xtrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# dffff = xtrain  #.drop([\"ids\", \"UNITID\", \"FTFTPCTPELL\", \"ST_FIPS\", \"LOCALE_31\"], axis = 1)\n",
    "# print(dffff.shape)\n",
    "# th = [0.001, 0.002, 0.03, 0.004, 0.05, 0.06]\n",
    "\n",
    "# # for t in th:\n",
    "# select = VarianceThreshold(threshold = 0.03)\n",
    "# select.fit(dffff)\n",
    "# const_columns = [column for column in dffff.columns if column not in dffff.columns[select.get_support()]]\n",
    "# print(len(const_columns))\n",
    "\n",
    "# xtrain = xtrain.drop(const_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xnot =  list(xtrain.columns[xtrain.columns.str.startswith(\"PELL\")])\n",
    "print(\"variables to be removed:\")\n",
    "print(len(xnot))\n",
    "print(\"remaining variables:\")\n",
    "\n",
    "features = xtrain.columns\n",
    "features2 = xtrain.columns.drop(xnot)\n",
    "\n",
    "print(len(features2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "poly = PolynomialFeatures(3)\n",
    "\n",
    "scaler.fit(xtrain[features])\n",
    "xtrain2 = pd.DataFrame(scaler.transform(xtrain[features]), columns = features)\n",
    "xvalid2 = pd.DataFrame(scaler.transform(xvalid[features]), columns = features)\n",
    "xtest2 = pd.DataFrame(scaler.transform(xtest[features]), columns = features)\n",
    "\n",
    "scaler.fit(xtrain[features2])\n",
    "xtrain3 = pd.DataFrame(scaler.transform(xtrain[features2]), columns = features2)\n",
    "xvalid3 = pd.DataFrame(scaler.transform(xvalid[features2]), columns = features2)\n",
    "xtest3 = pd.DataFrame(scaler.transform(xtest[features2]), columns = features2)\n",
    "\n",
    "print(\"      ORIGINAL -  xtrain before:\", xtrain.shape)\n",
    "print(\"        SCALED - xtrain2 before:\", xtrain2.shape)\n",
    "print(\"SCALED&REDUCED - xtrain3 before:\", xtrain3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for correlation between feature pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "poly = PolynomialFeatures(3)\n",
    "\n",
    "scaler.fit(xtrain[features])\n",
    "xtrain2 = pd.DataFrame(scaler.transform(xtrain[features]), columns = features)\n",
    "xvalid2 = pd.DataFrame(scaler.transform(xvalid[features]), columns = features)\n",
    "xtest2 = pd.DataFrame(scaler.transform(xtest[features]), columns = features)\n",
    "\n",
    "scaler.fit(xtrain[features2])\n",
    "xtrain3 = pd.DataFrame(scaler.transform(xtrain[features2]), columns = features2)\n",
    "xvalid3 = pd.DataFrame(scaler.transform(xvalid[features2]), columns = features2)\n",
    "xtest3 = pd.DataFrame(scaler.transform(xtest[features2]), columns = features2)\n",
    "\n",
    "print(\"      ORIGINAL -  xtrain before:\", xtrain.shape)\n",
    "print(\"        SCALED - xtrain2 before:\", xtrain2.shape)\n",
    "print(\"SCALED&REDUCED - xtrain3 before:\", xtrain3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALED AND REDUCED DATASET\n",
    "corrs = []\n",
    "contFeat = list(xtrain3.columns)\n",
    "contFeat_length = len(contFeat)\n",
    "\n",
    "for i in range(contFeat_length):\n",
    "    for j in range(i + 1, contFeat_length):\n",
    "        feati = xtrain3[contFeat[i]].values.flatten()\n",
    "        featj = xtrain3[contFeat[j]].values.flatten()\n",
    "\n",
    "        corr, _ = pearsonr(feati, featj)\n",
    "        corrs.append([corr, abs(corr), contFeat[i], contFeat[j]])\n",
    "correl = pd.DataFrame(corrs, columns = [\"P_Corr\", \"P_Corr_abs\", \"feat1\", \"feat2\"])\n",
    "################################\n",
    "grb = correl.groupby([\"feat1\", \"feat2\"]).count()\n",
    "grb.sort_values(\"P_Corr_abs\", ascending=False).to_csv(\"xtrain1_corrgroups.csv\")\n",
    "################################\n",
    "tot_var_pair = (contFeat_length * (contFeat_length - 1) / 2)\n",
    "num_var_g50 = len(correl[abs(correl[\"P_Corr\"]) > 0.5])\n",
    "pct_var_g50 = np.round(num_var_g50 / tot_var_pair * 100, 4)\n",
    "print(xtrain3.shape)\n",
    "print(int(tot_var_pair), \" : Total number of features pairs:\")\n",
    "print(num_var_g50, \"   : Number of features pairs with absolute Pearson Correl above 0.5:\")\n",
    "print(pct_var_g50, \"% : Percent of features pairs with absolute Pearson Correl above 0.5:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREDIT: Dr. Vanderheyden wrote this code.\n",
    "accuracies = []\n",
    "for f in features2:\n",
    "    log_reg = LogisticRegression(solver = \"saga\",\n",
    "                                 random_state = rand_state,\n",
    "                                 penalty = \"l1\",\n",
    "                                 class_weight = \"balanced\",\n",
    "                                 max_iter = 1000)\n",
    "    x = xtrain3[f].values.reshape(-1, 1)\n",
    "    y = y_train.reshape(-1, 1)\n",
    "    ## LIN ##############################\n",
    "    log_reg.fit(x, y)\n",
    "    acc, auc = get_acc_auc(y, log_reg.predict(x))\n",
    "    ## LOG #############################   \n",
    "    xl = np.log(x - np.min(x) + 1)\n",
    "    log_reg.fit(xl, y)\n",
    "    lcc, luc = get_acc_auc(y, log_reg.predict(xl))\n",
    "\n",
    "    if lcc / acc >= 1.1 or luc / auc >= 1.05:  # if bin accuracy is 110% of linear accuracy or ... AUC is 105% ...\n",
    "        xtrain3[f + \"_log\"] = xl\n",
    "        xvalid3[f + \"_log\"] = np.log(xvalid3[f].values.reshape(-1, 1) - np.min(xtrain3[f])+1)\n",
    "        xtest3[f + \"_log\"] = np.log(xtest3[f].values.reshape(-1, 1) - np.min(xtrain3[f])+1)\n",
    "    ## EXP #############################   \n",
    "    xe = np.exp(x)\n",
    "    log_reg.fit(xe, y)\n",
    "    ecc, euc = get_acc_auc(y, log_reg.predict(xe))\n",
    "\n",
    "    # if ecc / acc >= 1.1 or euc / auc >= 1.05: \n",
    "    #     xtrain3[f + \"_exp\"] = xe\n",
    "    #     xvalid3[f + \"_exp\"] = np.exp(xvalid3[f].values.reshape(-1, 1))\n",
    "    #     xtest3[f + \"_exp\"] = np.exp(xtest3[f].values.reshape(-1, 1))\n",
    "    ## POLY ############################# \n",
    "    poly.fit(x)\n",
    "    xp = poly.transform(x)\n",
    "    log_reg.fit(xp, y)\n",
    "    pcc, puc = get_acc_auc(y, log_reg.predict(xp))\n",
    "    # if pcc / acc >= 1.1 or puc / auc >= 1.05:  # if bin accuracy is 110% of linear accuracy or ... AUC is 105% ...\n",
    "    #     xtrain3[f + \"_p2\"] = x**2\n",
    "    #     xtrain3[f + \"_p3\"] = x**3\n",
    "    #     xvalid3[f + \"_p2\"] = (xvalid3[f].values)**2\n",
    "    #     xvalid3[f + \"_p3\"] = (xvalid3[f].values)**3\n",
    "    #     xtest3[f + \"_p2\"] = (xtest3[f].values)**2\n",
    "    #     xtest3[f + \"_p3\"] = (xtest3[f].values)**3\n",
    "    ## BIN #############################\n",
    "    xmin = x.min()\n",
    "    rnge = x.max() - xmin\n",
    "\n",
    "    xtrn = 0 + ((x - xmin) > 1 * rnge / 10) + ((x - xmin) > 2 * rnge / 10) + ((x - xmin) > 3 * rnge / 10) + ( # the objects in each\n",
    "                (x - xmin) > 4 * rnge / 10) + ((x - xmin) > 5 * rnge / 10) + ((x - xmin) > 6 * rnge / 10) + ( # bracket returns true\n",
    "                (x - xmin) > 7 * rnge / 10) + ((x - xmin) > 8 * rnge / 10) + ((x - xmin) > 9 * rnge / 10)     # or false \n",
    "    xval = 0 + ((xvalid3[f] - xmin) > 1 * rnge / 10) + ((xvalid3[f] - xmin) > 2 * rnge / 10) + ((xvalid3[f] - xmin) > 3 * rnge / 10) + (\n",
    "                (xvalid3[f] - xmin) > 4 * rnge / 10) + ((xvalid3[f] - xmin) > 5 * rnge / 10) + ((xvalid3[f] - xmin) > 6 * rnge / 10) + (\n",
    "                (xvalid3[f] - xmin) > 7 * rnge / 10) + ((xvalid3[f] - xmin) > 8 * rnge / 10) + ((xvalid3[f] - xmin) > 9 * rnge / 10)\n",
    "    xtst = 0 + ((xtest3[f] - xmin) > 1 * rnge / 10) + ((xtest3[f] - xmin) > 2 * rnge / 10) + ((xtest3[f] - xmin) > 5 * rnge / 10) + (\n",
    "                (xtest3[f] - xmin) > 3 * rnge / 10) + ((xtest3[f] - xmin) > 4 * rnge / 10) + ((xtest3[f] - xmin) > 6 * rnge / 10) + (\n",
    "                (xtest3[f] - xmin) > 7 * rnge / 10) + ((xtest3[f] - xmin) > 8 * rnge / 10) + ((xtest3[f] - xmin) > 9 * rnge / 10)\n",
    "                \n",
    "    encoder = TargetEncoder()\n",
    "\n",
    "    encoder.fit(xtrn, y)\n",
    "    xb = encoder.transform(xtrn)\n",
    "    log_reg.fit(xb, y)\n",
    "\n",
    "    bcc, buc = get_acc_auc(y, log_reg.predict(xb))\n",
    "\n",
    "    if bcc / acc >= 1.1 or buc / auc >= 1.05: # if bin accuracy is 110% of linear accuracy or ... AUC is 105% ...\n",
    "        xtrain3[f + \"_Bin\"] = xb\n",
    "        xvalid3[f + \"_Bin\"] = encoder.transform(xval)\n",
    "        xtest3[f + \"_Bin\"] = encoder.transform(xtst)\n",
    "    ## COMPLETION #############################\n",
    "    lDa = lcc / acc\n",
    "    eDa = ecc / acc\n",
    "    pDa = pcc / acc\n",
    "    bDa = bcc / acc\n",
    "    lda = luc / auc\n",
    "    eda = euc / auc\n",
    "    pda = puc / auc\n",
    "    bda = buc / auc\n",
    "    accuracies.append([f, acc, lcc, ecc, pcc, bcc, auc, luc, euc, puc, buc, lDa, eDa, pDa, bDa, lda, eda, pda, bda])\n",
    "###############################################\n",
    "\n",
    "colums = [\"Feature\",\"ACC: Linear\", \"ACC: Log\", \"ACC: Exp\", \"ACC: Poly3\",\"ACC: Bin\",\n",
    "                    \"AUC: Simple Linear\", \"AUC: Log\", \"AUC: Exp\",\"AUC: Poly3\", \"AUC: Bin\",\n",
    "                    \"ACC: LOG / Linear\", \"ACC: EXP / Linear\", \"ACC: Poly3 / Linear\", \"ACC: Bin / Linear\",\n",
    "                    \"AUC: LOG / Linear\", \"AUC: EXP / Linear\", \"AUC: Poly3 / Linear\", \"AUC: Bin / Linear\"]\n",
    "accDf = pd.DataFrame(accuracies, columns = colums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xtrain3.shape)\n",
    "accDf.to_csv(\"acc_df.csv\")\n",
    "accDf.loc[:, [\"Feature\", \"ACC: LOG / Linear\", \"ACC: EXP / Linear\", \"ACC: Poly3 / Linear\", \"ACC: Bin / Linear\",\n",
    "                         \"AUC: LOG / Linear\", \"AUC: EXP / Linear\", \"AUC: Poly3 / Linear\", \"AUC: Bin / Linear\"]\n",
    "             ].sort_values(\"ACC: LOG / Linear\", ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "ddrp_lst = [ 'GRAD_DEBT_MDN10YR'] #, 'TUITIONFEE_OUT_p2'] # ,'TUITIONFEE_IN_exp', 'TUITIONFEE_IN_p3', 'TUITIONFEE_OUT_p3', 'MALE_DEBT_MDN_p3', \n",
    "\n",
    "mutual_info = mutual_info_classif(xtrain3.drop(ddrp_lst, axis = 1), y_train)\n",
    "\n",
    "print(xtrain3.drop(ddrp_lst, axis = 1).shape)\n",
    "\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k = 10)\n",
    "sel_five_cols.fit(xtrain3.drop(ddrp_lst, axis = 1), y_train)\n",
    "lst = sel_five_cols.get_support()\n",
    "lst = xtrain3.drop(ddrp_lst, axis = 1).columns[lst]\n",
    "# xtrain4[lst]\n",
    "lst\n",
    "x_train3 = xtrain3[lst]\n",
    "x_test3 = xtest3[lst]\n",
    "x_valid3 = xvalid3[lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rechecking for correlation between feature pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCALED AND REDUCED DATASET\n",
    "corrs = []\n",
    "contFeat = list(x_train3.columns)\n",
    "contFeat_length = len(contFeat)\n",
    "\n",
    "for i in range(contFeat_length):\n",
    "    for j in range(i + 1, contFeat_length):\n",
    "        feati = x_train3[contFeat[i]].values.flatten()\n",
    "        featj = x_train3[contFeat[j]].values.flatten()\n",
    "\n",
    "        corr, _ = pearsonr(feati, featj)\n",
    "        corrs.append([corr, abs(corr), contFeat[i], contFeat[j]])\n",
    "correl = pd.DataFrame(corrs, columns = [\"P_Corr\", \"P_Corr_abs\", \"feat1\", \"feat2\"])\n",
    "################################\n",
    "grb = correl.groupby([\"feat1\", \"feat2\"]).count()\n",
    "grb.sort_values(\"P_Corr_abs\", ascending=False).to_csv(\"xtrain1_corrgroups.csv\")\n",
    "################################\n",
    "tot_var_pair = (contFeat_length * (contFeat_length - 1) / 2)\n",
    "num_var_g50 = len(correl[abs(correl[\"P_Corr\"]) > 0.5])\n",
    "pct_var_g50 = np.round(num_var_g50 / tot_var_pair * 100, 4)\n",
    "print(x_train3.shape)\n",
    "print(int(tot_var_pair), \" : Total number of features pairs:\")\n",
    "print(num_var_g50, \"   : Number of features pairs with absolute Pearson Correl above 0.5:\")\n",
    "print(pct_var_g50, \"% : Percent of features pairs with absolute Pearson Correl above 0.5:\")\n",
    "# correl.sort_values(\"P_Corr_abs\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# df = xtrain\n",
    "# features = xtrain.columns.values\n",
    "\n",
    "# pca = PCA()\n",
    "# components = pca.fit_transform(df[features])\n",
    "# labels = {\n",
    "#     str(i): f\"PC {i+1} ({var:.1f}%)\"\n",
    "#     for i, var in enumerate(pca.explained_variance_ratio_ * 100)\n",
    "# }\n",
    "\n",
    "# fig = px.scatter_matrix(\n",
    "#     components,\n",
    "#     labels=labels,\n",
    "#     dimensions=range(2),\n",
    "#     color=y_train.reshape(-1,)\n",
    "# )\n",
    "# fig.update_traces(diagonal_visible=True)\n",
    "# fig.show()\n",
    "\n",
    "# from pca import pca\n",
    "# xtrain_var = xtrain2.drop([\"PELL_DEBT_MDN\"], axis = 1)\n",
    "# xtest_var = xtest2.drop([\"PELL_DEBT_MDN\"], axis = 1)\n",
    "# xvalid_var = xvalid2.drop([\"PELL_DEBT_MDN\"], axis = 1)\n",
    "# k = 22\n",
    "\n",
    "# model = pca(n_components=k)\n",
    "\n",
    "# results = model.fit_transform(xtrain_var)\n",
    "\n",
    "# fig, ax = model.plot(n_components=50)\n",
    "# # fig, ax = model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = False, PC = [10,3,7,1,6,5,4,2,8,9,0])#np.arange(0,k,1))\n",
    "# fig, ax = model.biplot(y = y_train.reshape(-1,), n_feat=k, legend=True, cmap='PiYG', label = True, d3=True, figsize=(14, 14))\n",
    "# import scikitplot as skplt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ORIG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain FULL\n",
    "%matplotlib inline\n",
    "\n",
    "xtrain_var = xtrain\n",
    "xtest_var = xtest\n",
    "xvalid_var = xvalid\n",
    "\n",
    "initial_feature_names = list(xtrain_var.columns)\n",
    "\n",
    "pca = PCA(#n_components = 5,\n",
    "          random_state = rand_state) #  \n",
    "principalComponents = pca.fit_transform(xtrain_var)\n",
    "\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(pca.components_.shape[0])]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(pca.components_.shape[0])]\n",
    "\n",
    "pc_df = pd.DataFrame(data = principalComponents,\n",
    "                     columns = most_important_names)\n",
    "df = pd.DataFrame({'var': pca.explained_variance_ratio_})\n",
    "pca_df = pd.DataFrame(pca.fit_transform(xtrain_var),\n",
    "                      columns = most_important_names)\n",
    "\n",
    "print(df[0:4].sum())\n",
    "sns.scatterplot(x=range(1, pca_df.shape[1]+1),y=\"var\", data=df, color=\"c\");\n",
    "\n",
    "print('test average log-likelihood: ', pca.score(xtest_var))\n",
    "print('validation average log-likelihood: ', pca.score(xvalid_var))\n",
    "print('train average log-likelihood: ', pca.score(xtrain_var))\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca,\n",
    "                            title='PCA Component Explained Variances of Program offerings',\n",
    "                            target_explained_variance=0.8,\n",
    "                            ax=None,\n",
    "                            figsize=None,\n",
    "                            title_fontsize='large',\n",
    "                            text_fontsize='medium')\n",
    "plt.savefig(my_filesys_pth + 'images/ORIG/FULL/PCA/PCA_explainedvar.png')\n",
    "interest_variable = pd.DataFrame([most_important_names,\n",
    "                                  pca.explained_variance_ratio_]).T\n",
    "interest_variable.sort_values([1], ascending = False).head(5) # LPPPLUS_AMT DBRR1_FED_UGCOMP_DEN\n",
    "\n",
    "from pca import pca\n",
    "\n",
    "model = pca(n_components=10, random_state = rand_state)\n",
    "results = model.fit_transform(xtrain_var)\n",
    "\n",
    "model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = True, PC = [2, 0])\n",
    "plt.savefig(my_filesys_pth + 'images/ORIG/FULL/PCA/PCA_scatter.png')\n",
    "\n",
    "model.plot(n_components=10) \n",
    "plt.savefig(my_filesys_pth + 'images/ORIG/FULL/PCA/PCA_featureimportance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain REDUC\n",
    "ddrp_lst = ['GRAD_DEBT_MDN10YR',\"NOPELL_DEBT_N\", 'DBRR4_FED_UGCOMP_RT','FTFTPCTFLOAN']\n",
    "mutual_info = mutual_info_classif(xtrain.drop(ddrp_lst, axis = 1), y_train, random_state = rand_state)\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k = 10)\n",
    "sel_five_cols.fit(xtrain.drop(ddrp_lst, axis = 1), y_train)\n",
    "lst = sel_five_cols.get_support()\n",
    "lst = xtrain.drop(ddrp_lst, axis = 1).columns[lst]\n",
    "x_train = xtrain[lst]\n",
    "x_test = xtest[lst]\n",
    "x_valid = xvalid[lst]\n",
    "\n",
    "x_t1_lst = lst.copy()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "xtrain_var = x_train\n",
    "xtest_var = x_test\n",
    "xvalid_var = x_valid\n",
    "\n",
    "initial_feature_names = list(xtrain_var.columns)\n",
    "\n",
    "pca = PCA(#n_components = 5,\n",
    "          random_state = rand_state) #  \n",
    "principalComponents = pca.fit_transform(xtrain_var)\n",
    "\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(pca.components_.shape[0])]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(pca.components_.shape[0])]\n",
    "\n",
    "pc_df = pd.DataFrame(data = principalComponents,\n",
    "                     columns = most_important_names)\n",
    "df = pd.DataFrame({'var': pca.explained_variance_ratio_})\n",
    "pca_df = pd.DataFrame(pca.fit_transform(xtrain_var),\n",
    "                      columns = most_important_names)\n",
    "\n",
    "print(df[0:4].sum())\n",
    "sns.scatterplot(x=range(1, pca_df.shape[1]+1),y=\"var\", data=df, color=\"c\");\n",
    "\n",
    "print('test average log-likelihood: ', pca.score(xtest_var))\n",
    "print('validation average log-likelihood: ', pca.score(xvalid_var))\n",
    "print('train average log-likelihood: ', pca.score(xtrain_var))\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca,\n",
    "                            title='PCA Component Explained Variances of Program offerings',\n",
    "                            target_explained_variance=0.8,\n",
    "                            ax=None,\n",
    "                            figsize=None,\n",
    "                            title_fontsize='large',\n",
    "                            text_fontsize='medium')\n",
    "plt.savefig(my_filesys_pth + 'images/ORIG/REDUC/PCA/PCA_explainedvar.png')\n",
    "\n",
    "interest_variable = pd.DataFrame([most_important_names,\n",
    "                                  pca.explained_variance_ratio_]).T\n",
    "interest_variable.sort_values([1], ascending = False).head(10) # LPPPLUS_AMT DBRR1_FED_UGCOMP_DEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca\n",
    "model = pca(n_components=10, random_state = rand_state)\n",
    "results = model.fit_transform(xtrain_var)\n",
    "model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = True, PC = [0, 2])\n",
    "plt.savefig(my_filesys_pth + 'images/ORIG/REDUC/PCA/PCA_scatter.png')\n",
    "\n",
    "model.plot(n_components=10) \n",
    "plt.savefig(my_filesys_pth + 'images/ORIG/REDUC/PCA/PCA_featureimportance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STAND dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 FULL\n",
    "file_specific_pth = \"images/STAND/FULL/PCA/\"\n",
    "\n",
    "x_train2 = xtrain2\n",
    "x_test2 = xtest2\n",
    "x_valid2 = xvalid2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "xtrain_var = x_train2\n",
    "xtest_var = x_test2\n",
    "xvalid_var = x_valid2\n",
    "\n",
    "initial_feature_names = list(xtrain_var.columns)\n",
    "\n",
    "pca = PCA(#n_components = 80,\n",
    "          random_state = rand_state) #  \n",
    "principalComponents = pca.fit_transform(xtrain_var)\n",
    "\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(pca.components_.shape[0])]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(pca.components_.shape[0])]\n",
    "\n",
    "pc_df = pd.DataFrame(data = principalComponents,\n",
    "                     columns = most_important_names)\n",
    "df = pd.DataFrame({'var': pca.explained_variance_ratio_})\n",
    "pca_df = pd.DataFrame(pca.fit_transform(xtrain_var),\n",
    "                      columns = most_important_names)\n",
    "\n",
    "print(df[0:3].sum())\n",
    "sns.scatterplot(x=range(1, pca_df.shape[1]+1),y=\"var\", data=df, color=\"c\");\n",
    "\n",
    "print('test average log-likelihood: ', pca.score(xtest_var))\n",
    "print('validation average log-likelihood: ', pca.score(xvalid_var))\n",
    "print('train average log-likelihood: ', pca.score(xtrain_var))\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca,\n",
    "                            title='PCA Component Explained Variances of Program offerings',\n",
    "                            target_explained_variance=0.8,\n",
    "                            ax=None,\n",
    "                            figsize=None,\n",
    "                            title_fontsize='large',\n",
    "                            text_fontsize='medium')\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_explainedvar.png')\n",
    "interest_variable = pd.DataFrame([most_important_names,\n",
    "                                  pca.explained_variance_ratio_]).T\n",
    "interest_variable.sort_values([1], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca\n",
    "\n",
    "model = pca(n_components=80, random_state = rand_state)\n",
    "results = model.fit_transform(xtrain_var)\n",
    "# model.biplot(y = y_train.reshape(-1,), n_feat=3, legend=True, cmap='PiYG', label = False, d3=True, figsize=(14, 14))\n",
    "model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = True, PC = [7, 3])#np.arange(0,k,1)) 7 2\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_scatter.png')\n",
    "\n",
    "model.plot(n_components=4) \n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_featureimportance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 REDUC\n",
    "file_specific_pth = \"images/STAND/REDUC/PCA/\"\n",
    "\n",
    "mutual_info = mutual_info_classif(xtrain2.drop(\"GRAD_DEBT_MDN\", axis = 1), y_train, random_state = rand_state)\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k = 10)\n",
    "sel_five_cols.fit(xtrain2, y_train)\n",
    "lst = sel_five_cols.get_support()\n",
    "lst = xtrain2.columns[lst]\n",
    "x_train2 = xtrain2[lst]\n",
    "x_test2 = xtest2[lst]\n",
    "x_valid2 = xvalid2[lst]\n",
    "\n",
    "x_t2_lst = lst.copy()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "xtrain_var = x_train2\n",
    "xtest_var = x_test2\n",
    "xvalid_var = x_valid2\n",
    "\n",
    "initial_feature_names = list(xtrain_var.columns)\n",
    "\n",
    "pca = PCA(#n_components = 10,\n",
    "          random_state = rand_state) #  \n",
    "principalComponents = pca.fit_transform(xtrain_var)\n",
    "\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(pca.components_.shape[0])]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(pca.components_.shape[0])]\n",
    "\n",
    "pc_df = pd.DataFrame(data = principalComponents,\n",
    "                     columns = most_important_names)\n",
    "df = pd.DataFrame({'var': pca.explained_variance_ratio_})\n",
    "pca_df = pd.DataFrame(pca.fit_transform(xtrain_var),\n",
    "                      columns = most_important_names)\n",
    "\n",
    "print(df[0:3].sum())\n",
    "sns.scatterplot(x=range(1, pca_df.shape[1]+1),y=\"var\", data=df, color=\"c\");\n",
    "\n",
    "print('test average log-likelihood: ', pca.score(xtest_var))\n",
    "print('validation average log-likelihood: ', pca.score(xvalid_var))\n",
    "print('train average log-likelihood: ', pca.score(xtrain_var))\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca,\n",
    "                            title='PCA Component Explained Variances of Program offerings',\n",
    "                            target_explained_variance=0.8,\n",
    "                            ax=None,\n",
    "                            figsize=None,\n",
    "                            title_fontsize='large',\n",
    "                            text_fontsize='medium')\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_explainedvar.png')\n",
    "interest_variable = pd.DataFrame([most_important_names,\n",
    "                                  pca.explained_variance_ratio_]).T\n",
    "interest_variable.sort_values([1], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca\n",
    "\n",
    "model = pca(n_components=4, random_state = rand_state)\n",
    "results = model.fit_transform(xtrain_var)\n",
    "# model.biplot(y = y_train.reshape(-1,), n_feat=3, legend=True, cmap='PiYG', label = False, d3=True, figsize=(14, 14))\n",
    "model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = True, PC = [0, 1])#np.arange(0,k,1)) 7 2\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_scatter.png')\n",
    "\n",
    "model.plot(n_components=4) \n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_featureimportance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### STAND&TRANS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND&TRANS: xtrain3 FULL\n",
    "file_specific_pth = \"images/STAND_TRAN/FULL/PCA/\"\n",
    "# drrp = [\"CCBASIC_31_exp\", \"CCUGPROF_8_exp\", \"OMENRYP_FULLTIME_exp\", \"OMACHT8_FTFT_exp\", \"OPEFLAG_3_exp\", \"CCBASIC_25_exp\", \"CCUGPROF_0_exp\", \"INEXPFTE_exp\"]\n",
    "%matplotlib inline\n",
    "\n",
    "xtrain_var = xtrain3\n",
    "xtest_var = xtest3\n",
    "xvalid_var = xvalid3\n",
    "\n",
    "initial_feature_names = list(xtrain_var.columns)\n",
    "\n",
    "pca = PCA(#n_components = 80,\n",
    "          random_state = rand_state) #  \n",
    "principalComponents = pca.fit_transform(xtrain_var)\n",
    "\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(pca.components_.shape[0])]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(pca.components_.shape[0])]\n",
    "\n",
    "pc_df = pd.DataFrame(data = principalComponents,\n",
    "                     columns = most_important_names)\n",
    "df = pd.DataFrame({'var': pca.explained_variance_ratio_})\n",
    "pca_df = pd.DataFrame(pca.fit_transform(xtrain_var),\n",
    "                      columns = most_important_names)\n",
    "\n",
    "print(df[0:3].sum())\n",
    "sns.scatterplot(x=range(1, pca_df.shape[1]+1),y=\"var\", data=df, color=\"c\");\n",
    "\n",
    "print('test average log-likelihood: ', pca.score(xtest_var))\n",
    "print('validation average log-likelihood: ', pca.score(xvalid_var))\n",
    "print('train average log-likelihood: ', pca.score(xtrain_var))\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca,\n",
    "                            title='PCA Component Explained Variances of Program offerings',\n",
    "                            target_explained_variance=0.8,\n",
    "                            ax=None,\n",
    "                            figsize=None,\n",
    "                            title_fontsize='large',\n",
    "                            text_fontsize='medium')\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_explainedvar.png')\n",
    "interest_variable = pd.DataFrame([most_important_names,\n",
    "                                  pca.explained_variance_ratio_]).T\n",
    "interest_variable.sort_values([1], ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca\n",
    "\n",
    "model = pca(n_components=80, random_state = rand_state)\n",
    "results = model.fit_transform(xtrain_var)\n",
    "model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = True, PC = [0, 3])\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_scatter.png')\n",
    "\n",
    "model.plot(n_components=10) \n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_featureimportance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND&TRANS: xtrain3 REDUC\n",
    "file_specific_pth = \"images/STAND_TRAN/REDUC/PCA/\"\n",
    "ddrp_lst = ['GRAD_DEBT_MDN'] #,'TUITIONFEE_IN_exp', 'TUITIONFEE_IN_p3', 'TUITIONFEE_OUT_p3', 'MALE_DEBT_MDN_p3', 'TUITIONFEE_OUT_p2',\"NOPELL_DEBT_N_exp\", \"AVGFACSAL_exp\"]\n",
    "mutual_info = mutual_info_classif(xtrain3.drop(ddrp_lst, axis = 1), y_train, random_state=rand_state)\n",
    "sel_five_cols = SelectKBest(mutual_info_classif, k = 10)\n",
    "sel_five_cols.fit(xtrain3.drop(ddrp_lst, axis = 1), y_train)\n",
    "lst = sel_five_cols.get_support()\n",
    "lst = xtrain3.drop(ddrp_lst, axis = 1).columns[lst]\n",
    "x_train3 = xtrain3[lst]\n",
    "x_test3 = xtest3[lst]\n",
    "x_valid3 = xvalid3[lst]\n",
    "\n",
    "x_t3_lst = lst\n",
    "\n",
    "%matplotlib inline\n",
    "k = 50\n",
    "\n",
    "xtrain_var = x_train3\n",
    "xtest_var = x_test3\n",
    "xvalid_var = x_valid3\n",
    "print(xtrain_var.shape)\n",
    "\n",
    "initial_feature_names = list(xtrain_var.columns)\n",
    "\n",
    "pca = PCA(n_components = 10,\n",
    "          random_state = rand_state) #  \n",
    "principalComponents = pca.fit_transform(xtrain_var)\n",
    "\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(pca.components_.shape[0])]\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(pca.components_.shape[0])]\n",
    "\n",
    "pc_df = pd.DataFrame(data = principalComponents,\n",
    "                     columns = most_important_names)\n",
    "df = pd.DataFrame({'var': pca.explained_variance_ratio_})\n",
    "pca_df = pd.DataFrame(pca.fit_transform(xtrain_var),\n",
    "                      columns = most_important_names)\n",
    "\n",
    "print(df[0:2].sum())\n",
    "sns.scatterplot(x=range(1, pca_df.shape[1]+1),y=\"var\", data=df, color=\"c\");\n",
    "\n",
    "print('test average log-likelihood: ', pca.score(xtest_var))\n",
    "print('validation average log-likelihood: ', pca.score(xvalid_var))\n",
    "print('train average log-likelihood: ', pca.score(xtrain_var))\n",
    "\n",
    "skplt.decomposition.plot_pca_component_variance(pca,\n",
    "                            title='PCA Component Explained Variances of Program offerings',\n",
    "                            target_explained_variance=0.8,\n",
    "                            ax=None,\n",
    "                            figsize=None,\n",
    "                            title_fontsize='large',\n",
    "                            text_fontsize='medium')\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_explainedvar.png')\n",
    "interest_variable = pd.DataFrame([most_important_names,\n",
    "                                  pca.explained_variance_ratio_]).T\n",
    "interest_variable = interest_variable.sort_values([1], ascending = False)\n",
    "interest_variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pca import pca\n",
    "model = pca(n_components=5, random_state = rand_state)\n",
    "results = model.fit_transform(xtrain_var)\n",
    "model.scatter(y = y_train.reshape(-1,), legend=True, cmap='Pastel2_r', label = True, PC = [1, 4])#np.arange(0,k,1)) 1 4    2  1     3 0\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_scatter.png')\n",
    "\n",
    "model.plot(n_components=5) \n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'PCA_featureimportance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTHER Work\n",
    "# xtrain_var = xtrain\n",
    "# xtest_var = xtest\n",
    "# xvalid_var = xvalid\n",
    "\n",
    "# y_train_var = y_train\n",
    "# y_test_var = y_test\n",
    "# y_valid_var = y_valid\n",
    "\n",
    "# ccc = [0.001]\n",
    "# n_est = [90] # np.arange(10,100,10)# \n",
    "# penal = [\"l1\", \"l2\"]\n",
    "\n",
    "# logReg_lst = []\n",
    "\n",
    "# for cc in ccc:\n",
    "#     for nest in n_est:\n",
    "#         for p in penal:\n",
    "#             logReg = LogisticRegression(solver = \"saga\",\n",
    "#                                         random_state = rand_state, \n",
    "#                                         penalty = p, \n",
    "#                                         C = cc, \n",
    "#                                         class_weight = \"balanced\",\n",
    "#                                         max_iter = nest)\n",
    "#             logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "#             Tpred = logReg.predict(xtrain_var)\n",
    "#             vpred = logReg.predict(xvalid_var)\n",
    "#             tpred = logReg.predict(xtest_var)\n",
    "\n",
    "#             Tprob = logReg.predict_proba(xtrain_var)\n",
    "#             vprob = logReg.predict_proba(xvalid_var)\n",
    "#             tprob = logReg.predict_proba(xtest_var)\n",
    "\n",
    "#             logReg_lst.append([\"saga\", p, cc, nest, np.sum(logReg.coef_==0),\n",
    "#                             round(roc_auc_score(y_train_var, Tprob[:,1]), 4), round(roc_auc_score(y_test_var, tprob[:,1]), 4), round(roc_auc_score(y_valid_var, vprob[:,1]), 4),\n",
    "#                             round(1 - np.mean(abs(y_train_var - Tpred)), 4), round(1 - np.mean(abs(y_test_var - tpred)), 4), round(1 - np.mean(abs(y_valid_var- vpred)), 4),\n",
    "#                             ])\n",
    "\n",
    "# colums = [\"solver\", \"penalty\", \"C\", \"max_iter\", \"coef_eq_zero\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# logReg_outcomes = pd.DataFrame(logReg_lst, columns = colums)\n",
    "\n",
    "# # OTHER worrk\n",
    "# xtrain_var = x_train2\n",
    "# xtest_var = x_test2\n",
    "# xvalid_var = x_valid2\n",
    "\n",
    "# y_train_var = y_train\n",
    "# y_test_var = y_test\n",
    "# y_valid_var = y_valid\n",
    "\n",
    "# ccc = [100, 10, 1.0, 0.1, 0.01]\n",
    "# n_est = [10, 100, 500, 1000]\n",
    "# penal = [\"l1\", \"l2\"]\n",
    "\n",
    "# logReg_lst = []\n",
    "\n",
    "# for cc in ccc:\n",
    "#     for nest in n_est:\n",
    "#         for p in penal:\n",
    "#             logReg = LogisticRegression(solver = \"saga\",\n",
    "#                                         random_state = rand_state, \n",
    "#                                         penalty = p, \n",
    "#                                         C = cc, \n",
    "#                                         class_weight = \"balanced\",\n",
    "#                                         max_iter = nest)\n",
    "#             logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "#             Tpred = logReg.predict(xtrain_var)\n",
    "#             vpred = logReg.predict(xvalid_var)\n",
    "#             tpred = logReg.predict(xtest_var)\n",
    "\n",
    "#             Tprob = logReg.predict_proba(xtrain_var)\n",
    "#             vprob = logReg.predict_proba(xvalid_var)\n",
    "#             tprob = logReg.predict_proba(xtest_var)\n",
    "\n",
    "#             logReg_lst.append([\"saga\", p, cc, nest, np.sum(logReg.coef_==0),\n",
    "#                             round(roc_auc_score(y_train_var, Tprob[:,1]), 4), round(roc_auc_score(y_test_var, tprob[:,1]), 4), round(roc_auc_score(y_valid_var, vprob[:,1]), 4),\n",
    "#                             round(1 - np.mean(abs(y_train_var - Tpred)), 4), round(1 - np.mean(abs(y_test_var - tpred)), 4), round(1 - np.mean(abs(y_valid_var- vpred)), 4),\n",
    "#                             ])\n",
    "\n",
    "# colums = [\"solver\", \"penalty\", \"C\", \"max_iter\", \"coef_eq_zero\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# logReg_outcomes = pd.DataFrame(logReg_lst, columns = colums)\n",
    "# logReg_outcomes.sort_values(\"Test_Accurcy\", ascending = False).head(10)\n",
    "\n",
    "##### ORIGINAL DATAset\n",
    "# solver\tpenalty\tC\tmax_iter\tcoef_eq_zero\tTrain_AUC\tTest_AUC\tValid_AUC\tTrain_Accurcy\tTest_Accurcy\tValid_Accurcy\n",
    "# 0\tsaga\tl1\t100.0\t10\t1\t0.5715\t0.6148\t0.5841\t0.5775\t0.5857\t0.5654\n",
    "# 8\tsaga\tl1\t10.0\t10\t1\t0.5715\t0.6148\t0.5841\t0.5775\t0.5857\t0.5654\n",
    "# 1\tsaga\tl2\t100.0\t10\t1\t0.5715\t0.6148\t0.5841\t0.5775\t0.5857\t0.5654\n",
    "\n",
    "# SCALED AND REDUCED DATASET: xtrain3\n",
    "# xtrain_var = xtrain3\n",
    "# xtest_var = xtest3\n",
    "# xvalid_var = xvalid3\n",
    "\n",
    "# y_train_var = y_train\n",
    "# y_test_var = y_test\n",
    "# y_valid_var = y_valid\n",
    "\n",
    "# ccc = [100, 10, 1.0, 0.1, 0.01]\n",
    "# n_est = [90]\n",
    "# penal = [\"l1\", \"l2\"]\n",
    "\n",
    "# logReg_lst = []\n",
    "\n",
    "# for cc in ccc:\n",
    "#     for nest in n_est:\n",
    "#         for p in penal:\n",
    "#             params = [cc, nest, p]\n",
    "#             logReg = LogisticRegression(solver = \"saga\",\n",
    "#                                         random_state = rand_state, \n",
    "#                                         penalty = p, \n",
    "#                                         C = cc, \n",
    "#                                         class_weight = \"balanced\",\n",
    "#                                         max_iter = nest)\n",
    "#             logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "#             train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "#             outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#             if train_auc > best_train_auc:\n",
    "#                 best_train_auc = train_auc\n",
    "#                 b_tr_auc = outs\n",
    "#             if test_auc > best_test_auc:\n",
    "#                 best_test_auc = test_auc\n",
    "#                 b_ts_auc = outs\n",
    "#             if valid_auc > best_valid_auc:\n",
    "#                 best_valid_auc = valid_auc\n",
    "#                 b_v_auc = outs\n",
    "\n",
    "#             if train_accuracy > best_train_accuracy:\n",
    "#                 best_train_accuracy = train_accuracy\n",
    "#                 b_tr_acc = outs\n",
    "#             if test_accuracy > best_test_accuracy:\n",
    "#                 best_test_accuracy = test_accuracy\n",
    "#                 b_ts_acc = outs\n",
    "#             if valid_accuracy > best_valid_accuracy:\n",
    "#                 best_valid_accuracy = valid_accuracy\n",
    "#                 b_v_acc = outs\n",
    "\n",
    "#             logReg_lst.append([\"saga\", p, cc, nest, np.sum(logReg.coef_==0),\n",
    "#                                train_auc, test_auc, valid_auc,\n",
    "#                                train_accuracy, test_accuracy, valid_accuracy])\n",
    "\n",
    "# colums = [\"solver\", \"penalty\", \"C\", \"max_iter\", \"coef_eq_zero\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# logReg_outcomes = pd.DataFrame(logReg_lst, columns = colums)\n",
    "\n",
    "# logReg_outcomes.sort_values(\"Test_Accurcy\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain FULL\n",
    "file_specific_pth = \"images/ORIG/FULL/LogReg/\"\n",
    "\n",
    "xtrain_var = xtrain\n",
    "xtest_var = xtest\n",
    "xvalid_var = xvalid\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "ccc = [0.0001]\n",
    "n_est = [90] # np.arange(10,100,10)# \n",
    "penal = [\"l1\"]\n",
    "\n",
    "logReg_lst = []\n",
    "\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = p, \n",
    "                            C = cc, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = nest)\n",
    "logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: REDUC\n",
    "file_specific_pth = \"images/ORIG/REDUC/LogReg/\"\n",
    "\n",
    "xtrain_var = x_train[x_t1_lst]\n",
    "xtest_var = x_test[x_t1_lst]\n",
    "xvalid_var = x_valid[x_t1_lst]\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l2\", \n",
    "                            C = 0.001, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 100)\n",
    "logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 FULL\n",
    "file_specific_pth = \"images/STAND/FULL/LogReg/\"\n",
    "\n",
    "xtrain_var = xtrain2\n",
    "xtest_var = xtest2\n",
    "xvalid_var = xvalid2\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l2\", \n",
    "                            C = 0.01, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 100)\n",
    "logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 REDUC\n",
    "file_specific_pth = \"images/STAND/REDUC/LogReg/\"\n",
    "\n",
    "xtrain_var = xtrain2[x_t2_lst]\n",
    "xtest_var = xtest2[x_t2_lst]\n",
    "xvalid_var = xvalid2[x_t2_lst]\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "ccc = [0.01]\n",
    "n_est = [100] # np.arange(10,100,10)# \n",
    "penal = [\"l1\"]\n",
    "\n",
    "logReg_lst = []\n",
    "\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = p, \n",
    "                            C = cc, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = nest)\n",
    "logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain3 FULL\n",
    "file_specific_pth = \"images/STAND_TRAN/FULL/LogReg/\"\n",
    "\n",
    "xtrain_var = xtrain3\n",
    "xtest_var = xtest3\n",
    "xvalid_var = xvalid3\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l1\", \n",
    "                            C = 0.01, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 90)\n",
    "logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND&TRANS: xtrain3 REDUC\n",
    "file_specific_pth = \"images/STAND_TRAN/REDUC/LogReg/\"\n",
    "\n",
    "xtrain_var = x_train3[x_t3_lst]\n",
    "xtest_var = x_test3[x_t3_lst]\n",
    "xvalid_var = x_valid3[x_t3_lst]\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l2\", \n",
    "                            C = 0.1, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 90)\n",
    "logReg.fit(xtrain_var, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, xtrain_var, xtest_var, xvalid_var, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LG_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Regression with the PCA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other work\n",
    "# 101\t     saga\tl2\t    100.00\t  1500\t      0\t        0.9477\t    0.9374\t    0.9469\t    0.8737\t        0.867\t        0.866\t        -0.0103\t            0.0103\n",
    "# 101\t     saga\tl1\t    80.00\t  100\t      0\t        0.9495\t    0.9399\t    0.9465\t    0.8750\t        0.866\t        0.875\t        -0.0096\t            0.0096\n",
    "# xtrain_var = x_train3\n",
    "# xtest_var = x_test3\n",
    "# xvalid_var = x_valid3\n",
    "\n",
    "# y_train_var = y_train\n",
    "# y_test_var = y_test\n",
    "# y_valid_var = y_valid\n",
    "\n",
    "\n",
    "# n_comp = np.array(range(1,x_train3.shape[1], 1)) #[2, 18, 24, 101] # \n",
    "# ccc = [1, 0.1, 0.001]\n",
    "# n_est = [90, 200] # np.arange(10,100,10)# \n",
    "# penal = [\"l2\", \"l1\"]\n",
    "# logReg_lst_pca = []\n",
    "\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# for nc in n_comp:\n",
    "#     for p in penal:\n",
    "#         for cc in ccc:\n",
    "#             for nest in n_est:\n",
    "#                 params = [nc, p, cc, nest]\n",
    "\n",
    "#                 pca = PCA(n_components = nc)\n",
    "#                 pca.fit(xtrain_var)\n",
    "\n",
    "#                 train_img = pca.transform(xtrain_var)\n",
    "#                 test_img = pca.transform(xtest_var)\n",
    "#                 valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "#                 logReg = LogisticRegression(solver = \"saga\",\n",
    "#                                             random_state = rand_state, \n",
    "#                                             penalty = p, \n",
    "#                                             C = cc, \n",
    "#                                             class_weight = \"balanced\",\n",
    "#                                             max_iter = nest)\n",
    "#                 logReg.fit(train_img, y_train_var)\n",
    "\n",
    "#                 train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "#                 outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                 if train_auc > best_train_auc:\n",
    "#                     best_train_auc = train_auc\n",
    "#                     b_tr_auc = outs\n",
    "#                 if test_auc > best_test_auc:\n",
    "#                     best_test_auc = test_auc\n",
    "#                     b_ts_auc = outs\n",
    "#                 if valid_auc > best_valid_auc:\n",
    "#                     best_valid_auc = valid_auc\n",
    "#                     b_v_auc = outs\n",
    "\n",
    "#                 if train_accuracy > best_train_accuracy:\n",
    "#                     best_train_accuracy = train_accuracy\n",
    "#                     b_tr_acc = outs\n",
    "#                 if test_accuracy > best_test_accuracy:\n",
    "#                     best_test_accuracy = test_accuracy\n",
    "#                     b_ts_acc = outs\n",
    "#                 if valid_accuracy > best_valid_accuracy:\n",
    "#                     best_valid_accuracy = valid_accuracy\n",
    "#                     b_v_acc = outs\n",
    "\n",
    "#                 logReg_lst_pca.append([nc, \"saga\", p, cc, nest, np.sum(logReg.coef_==0),\n",
    "#                                        train_auc, test_auc, valid_auc,\n",
    "#                                        train_accuracy, test_accuracy, valid_accuracy]) \n",
    "\n",
    "# colums = [\"num_components\", \"solver\", \"penalty\", \"C\", \"max_iter\", \"coef_eq_zero\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# logReg_outcomes = pd.DataFrame(logReg_lst_pca, columns = colums)\n",
    "\n",
    "# logReg_outcomes.sort_values(\"Test_Accurcy\", ascending=False).head(20)\n",
    "\n",
    "# print(\"Best Training Accuracy: \", best_train_accuracy, b_tr_auc)\n",
    "# print(\"Best     Test Accuracy: \", best_test_accuracy, b_ts_auc)\n",
    "# print(\"Best    Valid Accuracy: \", best_valid_accuracy, b_v_auc)\n",
    "\n",
    "# print(\"Best      Training AUC: \", best_train_auc, b_tr_acc)\n",
    "# print(\"Best          Test AUC: \", best_test_auc, b_ts_acc)\n",
    "# print(\"Best         Valid AUC: \", best_valid_auc, b_v_acc)\n",
    "\n",
    "# logReg_outcomes = pd.DataFrame(logReg_lst_pca, columns = colums)\n",
    "# logReg_outcomes[\"AUC_traintest_diff\"] = logReg_outcomes[\"Test_AUC\"] - logReg_outcomes[\"Train_AUC\"]\n",
    "# logReg_outcomes[\"ABS_AUC_traintest_diff\"] = abs(logReg_outcomes[\"Test_AUC\"] - logReg_outcomes[\"Train_AUC\"])\n",
    "# logReg_outcomes[\"max_acc_ratio\"] = round(((logReg_outcomes[\"Test_Accurcy\"] / logReg_outcomes[\"Test_Accurcy\"].max()) - 1) * 100, 4)\n",
    "# logReg_outcomes.sort_values(\"ABS_AUC_traintest_diff\", ascending=True).head(3)\n",
    "# logReg_outcomes.sort_values(\"Test_Accurcy\", ascending=False)\n",
    "\n",
    "# num_comp solver\tpenalty\tC\t  max_iter\tcoef_eq_zero\tTrain_AUC\tTest_AUC\tValid_AUC\tTrain_Accurcy\tTest_Accurcy\tValid_Accurcy\tAUC_traintest_diff ABS_AUC_traintest_diff\n",
    "# 101\t     saga\tl2\t    0.001\t  1000\t      0\t        0.9321\t    0.9318\t    0.9362\t    0.8494\t        0.848\t        0.861\t        -0.0003\t            0.0003\n",
    "# 101\t     saga\tl2\t    90.00\t  1500\t      0\t        0.9475\t    0.9392\t    0.9467\t    0.8729\t        0.865\t        0.871\t        -0.0083\t            0.0083\n",
    "# 101\t     saga\tl1\t    90.00\t  500\t      0\t        0.9465\t    0.9378\t    0.9447\t    0.8703\t        0.864\t        0.865\t        -0.0087\t            0.0087\n",
    "# 101\t     saga\tl1\t    80.00\t  1000\t      0\t        0.9489\t    0.9389\t    0.9475\t    0.8742\t        0.863\t        0.882\t        -0.0100\t            0.0100\n",
    "# 101\t     saga\tl2\t    100.00\t  1500\t      0\t        0.9477\t    0.9374\t    0.9469\t    0.8737\t        0.867\t        0.866\t        -0.0103\t            0.0103\n",
    "# 101\t     saga\tl1\t    80.00\t  100\t      0\t        0.9495\t    0.9399\t    0.9465\t    0.8750\t        0.866\t        0.875\t        -0.0096\t            0.0096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain FULL\n",
    "file_specific_pth = \"images/ORIG/FULL/LogRegPCA/\"\n",
    "\n",
    "xtrain_var = xtrain\n",
    "xtest_var = xtest\n",
    "xvalid_var = xvalid\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA(n_components = 3)\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pca.transform(xtrain_var)\n",
    "test_img = pca.transform(xtest_var)\n",
    "valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l1\", \n",
    "                            C = 0.001, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 200)\n",
    "logReg.fit(train_img, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain REDUC\n",
    "file_specific_pth = \"images/ORIG/REDUC/LogRegPCA/\"\n",
    "\n",
    "xtrain_var = x_train[x_t1_lst]\n",
    "xtest_var = x_test[x_t1_lst]\n",
    "xvalid_var = x_valid[x_t1_lst]\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pca.transform(xtrain_var)\n",
    "test_img = pca.transform(xtest_var)\n",
    "valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l1\", \n",
    "                            C = .001, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 100)\n",
    "logReg.fit(train_img, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 FULL\n",
    "file_specific_pth = \"images/STAND/FULL/LogRegPCA/\"\n",
    "\n",
    "xtrain_var = xtrain2\n",
    "xtest_var = xtest2\n",
    "xvalid_var = xvalid2\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA(n_components = 80)\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pca.transform(xtrain_var)\n",
    "test_img = pca.transform(xtest_var)\n",
    "valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l1\", \n",
    "                            C = 1, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 200)\n",
    "logReg.fit(train_img, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 REDUC\n",
    "file_specific_pth = \"images/STAND/REDUC/LogRegPCA/\"\n",
    "\n",
    "xtrain_var = x_train2[x_t2_lst]\n",
    "xtest_var = x_test2[x_t2_lst]\n",
    "xvalid_var = x_valid2[x_t2_lst]\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pca.transform(xtrain_var)\n",
    "test_img = pca.transform(xtest_var)\n",
    "valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l1\", \n",
    "                            C = 0.01, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 200)\n",
    "logReg.fit(train_img, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRAN: xtrain3 FULL\n",
    "file_specific_pth = \"images/STAND_TRAN/FULL/LogRegPCA/\"\n",
    "\n",
    "xtrain_var = xtrain3\n",
    "xtest_var = xtest3\n",
    "xvalid_var = xvalid3\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pca.transform(xtrain_var)\n",
    "test_img = pca.transform(xtest_var)\n",
    "valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l2\", \n",
    "                            C = 0.01, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 200)\n",
    "logReg.fit(train_img, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRAN: xtrain3 REDUC\n",
    "file_specific_pth = \"images/STAND_TRAN/REDUC/LogRegPCA/\"\n",
    "\n",
    "xtrain_var = x_train3[x_t3_lst]\n",
    "xtest_var = x_test3[x_t3_lst]\n",
    "xvalid_var = x_valid3[x_t3_lst]\n",
    "\n",
    "y_train_var = y_train\n",
    "y_test_var = y_test\n",
    "y_valid_var = y_valid\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pca.transform(xtrain_var)\n",
    "test_img = pca.transform(xtest_var)\n",
    "valid_img = pca.transform(xvalid_var)\n",
    "\n",
    "logReg = LogisticRegression(solver = \"saga\",\n",
    "                            random_state = rand_state, \n",
    "                            penalty = \"l2\", \n",
    "                            C = 0.01, \n",
    "                            class_weight = \"balanced\",\n",
    "                            max_iter = 200)\n",
    "logReg.fit(train_img, y_train_var)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(logReg, train_img, test_img, valid_img, y_train_var, y_test_var, y_valid_var)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(logReg, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, logReg.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = logReg.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'LGPCA_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1890\t80\tauto\tuniform\teuclidean\t1\t0.9054\t0.9117\t0.9145\t0.5235\t0.5296\t0.5234\t0.0063\t0.0\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# knc_lst = []\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(xtrain)\n",
    "\n",
    "# x_train = scaler.transform(xtrain)\n",
    "# x_test = scaler.transform(xtest)\n",
    "# x_valid = scaler.transform(xvalid)\n",
    "\n",
    "# nn = range(5, 105, 5) # [28, 29, 30, 31, 32, 33, 34, 35]\n",
    "# lef = [1, 6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81, 86, 91, 96, 101]\n",
    "# wgt = ['uniform']\n",
    "# met = ['euclidean']\n",
    "\n",
    "# mod_lst = []\n",
    "\n",
    "# for n in nn:\n",
    "#     for w in wgt:\n",
    "#         for m in met:\n",
    "#             for l in lef:\n",
    "#                 params = [n, w, m, l]\n",
    "#                 knc = KNeighborsClassifier(leaf_size=l,\n",
    "#                                            metric = m,\n",
    "#                                            n_neighbors = n,\n",
    "#                                            weights = w,\n",
    "#                                            algorithm = 'auto'\n",
    "#                                            )\n",
    "\n",
    "#                 knc.fit(x_train, y_train)\n",
    "\n",
    "#                 train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(knc, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "#                 outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                 if train_auc > best_train_auc:\n",
    "#                     best_train_auc = train_auc\n",
    "#                     b_tr_auc = outs\n",
    "#                 if test_auc > best_test_auc:\n",
    "#                     best_test_auc = test_auc\n",
    "#                     b_ts_auc = outs\n",
    "#                 if valid_auc > best_valid_auc:\n",
    "#                     best_valid_auc = valid_auc\n",
    "#                     b_v_auc = outs\n",
    "\n",
    "#                 if train_accuracy > best_train_accuracy:\n",
    "#                     best_train_accuracy = train_accuracy\n",
    "#                     b_tr_acc = outs\n",
    "#                 if test_accuracy > best_test_accuracy:\n",
    "#                     best_test_accuracy = test_accuracy\n",
    "#                     b_ts_acc = outs\n",
    "#                 if valid_accuracy > best_valid_accuracy:\n",
    "#                     best_valid_accuracy = valid_accuracy\n",
    "#                     b_v_acc = outs\n",
    "\n",
    "#                 knc_lst.append([n, \"auto\", w, m, l,\n",
    "#                                 round(roc_auc_score(y_train, Tprob[:,1]), 4), round(roc_auc_score(y_test, tprob[:,1]), 4), round(roc_auc_score(y_valid, vprob[:,1]), 4),\n",
    "#                                 round(1 - np.mean(abs(y_train - Tpred)), 4), round(1 - np.mean(abs(y_test - tpred)), 4), round(1 - np.mean(abs(y_valid- vpred)), 4),\n",
    "#                             ])\n",
    "\n",
    "# colums = [\"near_neigh\",  \"algorith\",\n",
    "#           \"weight\", \"metric\", \"leaf_size\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# knc_outcome = pd.DataFrame(knc_lst, columns = colums)\n",
    "\n",
    "# 1890\t80\tauto\tuniform\teuclidean\t1\t0.9054\t0.9117\t0.9145\t0.5235\t0.5296\t0.5234\t0.0063\t0.0\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# train_y = pd.DataFrame(y_train)\n",
    "\n",
    "# knc_lst = []\n",
    "\n",
    "# # scaler = StandardScaler()\n",
    "# # scaler.fit(xtrain3)\n",
    "\n",
    "# x_train_var = x_train3\n",
    "# x_test_var = x_test3\n",
    "# x_valid_var = x_valid3\n",
    "\n",
    "# nn = range(20, 101, 20) # [28, 29, 30, 31, 32, 33, 34, 35]\n",
    "# lef = [6]\n",
    "# wgt = ['uniform', \"distance\"]\n",
    "# met = ['euclidean']\n",
    "# n_comp = np.array(range(1, x_train_var.shape[1],1))\n",
    "\n",
    "# for nc in n_comp:\n",
    "#     for n in nn:\n",
    "#         for w in wgt:\n",
    "#             for m in met:\n",
    "#                 for l in lef:\n",
    "#                     params = [nc, n, w, m, l]\n",
    "\n",
    "#                     pca = PCA(n_components = nc, random_state = rand_state)\n",
    "#                     pca.fit(xtrain_var)\n",
    "\n",
    "#                     train_img = pd.DataFrame(pca.transform(xtrain_var))\n",
    "#                     test_img = pd.DataFrame(pca.transform(xtest_var))\n",
    "#                     valid_img = pd.DataFrame(pca.transform(xvalid_var))\n",
    "#                     knc = KNeighborsClassifier(leaf_size=l,\n",
    "#                                             metric = m,\n",
    "#                                             n_neighbors = n,\n",
    "#                                             weights = w,\n",
    "#                                             algorithm = 'auto')\n",
    "\n",
    "#                     knc.fit(train_img, train_y)\n",
    "\n",
    "#                     train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(knc, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "#                     outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                     if train_auc > best_train_auc:\n",
    "#                         best_train_auc = train_auc\n",
    "#                         b_tr_auc = outs\n",
    "#                     if test_auc > best_test_auc:\n",
    "#                         best_test_auc = test_auc\n",
    "#                         b_ts_auc = outs\n",
    "#                     if valid_auc > best_valid_auc:\n",
    "#                         best_valid_auc = valid_auc\n",
    "#                         b_v_auc = outs\n",
    "\n",
    "#                     if train_accuracy > best_train_accuracy:\n",
    "#                         best_train_accuracy = train_accuracy\n",
    "#                         b_tr_acc = outs\n",
    "#                     if test_accuracy > best_test_accuracy:\n",
    "#                         best_test_accuracy = test_accuracy\n",
    "#                         b_ts_acc = outs\n",
    "#                     if valid_accuracy > best_valid_accuracy:\n",
    "#                         best_valid_accuracy = valid_accuracy\n",
    "#                         b_v_acc = outs\n",
    "\n",
    "#                     knc_lst.append([nc, n, \"auto\", w, m, l,\n",
    "#                                     round(roc_auc_score(y_train, Tprob[:,1]), 4), round(roc_auc_score(y_test, tprob[:,1]), 4), round(roc_auc_score(y_valid, vprob[:,1]), 4),\n",
    "#                                     round(1 - np.mean(abs(y_train - Tpred)), 4), round(1 - np.mean(abs(y_test - tpred)), 4), round(1 - np.mean(abs(y_valid- vpred)), 4),\n",
    "#                                 ])\n",
    "\n",
    "# colums = [\"n_comp\",\"near_neigh\", \"algorith\",\n",
    "#           \"weight\", \"metric\", \"leaf_size\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# knc_outcome = pd.DataFrame(knc_lst, columns = colums)\n",
    "\n",
    "# print(\"Best Training Accuracy: \", best_train_accuracy, b_tr_auc)\n",
    "# print(\"Best     Test Accuracy: \", best_test_accuracy, b_ts_auc)\n",
    "# print(\"Best    Valid Accuracy: \", best_valid_accuracy, b_v_auc)\n",
    "\n",
    "# print(\"Best      Training AUC: \", best_train_auc, b_tr_acc)\n",
    "# print(\"Best          Test AUC: \", best_test_auc, b_ts_acc)\n",
    "# print(\"Best         Valid AUC: \", best_valid_auc, b_v_acc)\n",
    "\n",
    "# knc_outcome[\"ABS_AUC_traintest_diff\"] = abs(knc_outcome[\"Test_AUC\"] - knc_outcome[\"Train_AUC\"])\n",
    "# knc_outcome[\"max_acc_ratio\"] = round(((knc_outcome[\"Test_Accurcy\"] / knc_outcome[\"Test_Accurcy\"].max()) - 1) * 100, 4)\n",
    "# df = knc_outcome[knc_outcome[\"Train_AUC\"] < 1].sort_values(\"Train_AUC\", ascending = False)\n",
    "# df[df[\"Test_AUC\"] > 0.9].sort_values(\"Test_AUC\", ascending = False).head(50)\n",
    "# # knc_outcome.sort_values(\"Test_AUC\", ascending = False).head(50) # 0.9134\n",
    "# # knc_outcome.sort_values(\"Test_Accurcy\", ascending = False).head(50) # 0.5296\n",
    "# df.sort_values(\"Test_Accurcy\", ascending=False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 FULL\n",
    "file_specific_pth = \"images/STAND/FULL/KNN/\"\n",
    "\n",
    "x_train_var = xtrain2\n",
    "x_test_var = xtest2\n",
    "x_valid_var = xvalid2\n",
    "train_y = pd.DataFrame(y_train)\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "pca = PCA(n_components = 2, random_state = rand_state)\n",
    "pca.fit(x_train_var)\n",
    "\n",
    "train_img = pd.DataFrame(pca.transform(x_train_var))\n",
    "test_img = pd.DataFrame(pca.transform(x_test_var))\n",
    "valid_img = pd.DataFrame(pca.transform(x_valid_var))\n",
    "knc = KNeighborsClassifier(leaf_size=100,\n",
    "                           metric = \"euclidean\",\n",
    "                           n_neighbors = 35,\n",
    "                           weights = \"distance\",\n",
    "                           algorithm = 'auto')\n",
    "\t\n",
    "knc.fit(train_img, train_y)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(knc, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(knc, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'KNN_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, knc.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = knc.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'KNN_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 REDUC\n",
    "file_specific_pth = \"images/STAND/REDUC/KNN/\"\n",
    "\n",
    "x_train_var = x_train2[x_t2_lst]\n",
    "x_test_var = x_test2[x_t2_lst]\n",
    "x_valid_var = x_valid2[x_t2_lst]\n",
    "\n",
    "pca = PCA(n_components = 2, random_state = rand_state)\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pd.DataFrame(pca.transform(xtrain_var))\n",
    "test_img = pd.DataFrame(pca.transform(xtest_var))\n",
    "valid_img = pd.DataFrame(pca.transform(xvalid_var))\n",
    "knc = KNeighborsClassifier(leaf_size=100,\n",
    "                           metric = \"euclidean\",\n",
    "                           n_neighbors = 35,\n",
    "                           weights = \"distance\",\n",
    "                           algorithm = 'auto')\n",
    "\t\n",
    "knc.fit(train_img, train_y)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(knc, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(knc, test_img, y_test)\n",
    "cm = confusion_matrix(y_test, knc.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = knc.classes_).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRANS: xtrain3 FULL\n",
    "file_specific_pth = \"images/STAND_TRAN/FULL/KNN/\"\n",
    "\n",
    "x_train_var = xtrain3\n",
    "x_test_var = xtest3\n",
    "x_valid_var = xvalid3\n",
    "\n",
    "train_y = pd.DataFrame(y_train.reshape(-1,))\n",
    "\n",
    "pca = PCA(n_components = 2, random_state = rand_state)\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pd.DataFrame(pca.transform(xtrain_var))\n",
    "test_img = pd.DataFrame(pca.transform(xtest_var))\n",
    "valid_img = pd.DataFrame(pca.transform(xvalid_var))\n",
    "knc = KNeighborsClassifier(leaf_size=50,\n",
    "                           metric = \"euclidean\",\n",
    "                           n_neighbors = 35,\n",
    "                           weights = \"uniform\",\n",
    "                           algorithm = 'auto')\n",
    "\n",
    "knc.fit(train_img, train_y)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(knc, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(knc, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'KNN_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, knc.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = knc.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'KNN_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRANS: xtrain3 REDUC\n",
    "file_specific_pth = \"images/STAND_TRAN/REDUC/KNN/\"\n",
    "\n",
    "x_train_var = x_train3[x_t3_lst]\n",
    "x_test_var = x_test3[x_t3_lst]\n",
    "x_valid_var = x_valid3[x_t3_lst]\n",
    "\n",
    "pca = PCA(n_components = 2, random_state = rand_state)\n",
    "pca.fit(xtrain_var)\n",
    "\n",
    "train_img = pd.DataFrame(pca.transform(xtrain_var))\n",
    "test_img = pd.DataFrame(pca.transform(xtest_var))\n",
    "valid_img = pd.DataFrame(pca.transform(xvalid_var))\n",
    "knc = KNeighborsClassifier(leaf_size=50,\n",
    "                           metric = \"euclidean\",\n",
    "                           n_neighbors = 35,\n",
    "                           weights = \"uniform\",\n",
    "                           algorithm = 'auto')\n",
    "\n",
    "knc.fit(train_img, train_y)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(knc, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "    best_train_auc = train_auc\n",
    "    b_tr_auc = outs\n",
    "if test_auc > best_test_auc:\n",
    "    best_test_auc = test_auc\n",
    "    b_ts_auc = outs\n",
    "if valid_auc > best_valid_auc:\n",
    "    best_valid_auc = valid_auc\n",
    "    b_v_auc = outs\n",
    "\n",
    "if train_accuracy > best_train_accuracy:\n",
    "    best_train_accuracy = train_accuracy\n",
    "    b_tr_acc = outs\n",
    "if test_accuracy > best_test_accuracy:\n",
    "    best_test_accuracy = test_accuracy\n",
    "    b_ts_acc = outs\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "    best_valid_accuracy = valid_accuracy\n",
    "    b_v_acc = outs\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(knc, test_img, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'KNN_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, knc.predict(test_img))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = knc.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'KNN_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old work\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "train_x = pd.DataFrame(xtrain2)\n",
    "test_x = pd.DataFrame(xtest2)\n",
    "valid_x = pd.DataFrame(xvalid2)\n",
    "\n",
    "train_y = pd.DataFrame(y_train)\n",
    "test_y = pd.DataFrame(y_test)\n",
    "valid_y = pd.DataFrame(y_valid)\n",
    "\n",
    "x1 = train_x[(train_y == 1).values]\n",
    "y1 = train_y[(train_y == 1).values]\n",
    "\n",
    "x, y = resample(x1, y1,\n",
    "                replace = True,\n",
    "                n_samples = (len(train_y) - 2*sum(train_y)),\n",
    "                random_state = rand_state)\n",
    "\n",
    "xt = pd.concat([train_x, x])\n",
    "yt = pd.concat([train_y, y])\n",
    "\n",
    "xs, ys = shuffle(xt, yt, \n",
    "                 random_state = rand_state)\n",
    "\n",
    "xgb = XGBClassifier(learning_rate = 0.10, \n",
    "                min_split_loss = 0,\n",
    "                max_depth = 2,\n",
    "                gamma = 0.5,\n",
    "                min_child_weight = 1,\n",
    "                max_delta_step = 0,\n",
    "                subsample = 1,\n",
    "                n_estimators = 400)\n",
    "\n",
    "eval_set = [(train_x, train_y), (valid_x, valid_y)]\n",
    "\n",
    "xgb.fit(xs, ys, \n",
    "        eval_metric='auc', \n",
    "        eval_set = eval_set)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, train_x, test_x, valid_x, train_y, test_y, valid_y)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy, b_tr_auc)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy, b_ts_auc)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy, b_v_auc)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc, b_tr_acc)\n",
    "print(\"Best          Test AUC: \", best_test_auc, b_ts_acc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc, b_v_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(xgb, xtrain2)\n",
    "shap_values = explainer(xtrain2)\n",
    "\n",
    "shap.plots.waterfall(shap_values[0])\n",
    "\n",
    "shap.plots.scatter(shap_values[:,\"ACCREDAGENCY Encoded\"])\n",
    "\n",
    "shap.plots.bar(shap_values)\n",
    "\n",
    "shap.plots.bar(shap_values[1])\n",
    "\n",
    "shap.plots.beeswarm(shap_values,\n",
    "                    order = shap_values.abs.max(0),\n",
    "                    color=plt.get_cmap(\"PuBu_r\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgb)\n",
    "\n",
    "expected_value = explainer.expected_value\n",
    "\n",
    "if isinstance(expected_value, list):\n",
    "    expected_value = expected_value[1]\n",
    "print(f\"Explainer expected value: {expected_value}\")\n",
    "\n",
    "select = range(20)\n",
    "features = xtrain2.iloc[select]\n",
    "features_display = xtrain2.loc[features.index]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    shap_values = explainer.shap_values(features)[1]\n",
    "    shap_interaction_values = explainer.shap_interaction_values(features)\n",
    "    \n",
    "if isinstance(shap_interaction_values, list):\n",
    "    shap_interaction_values = shap_interaction_values[1]\n",
    "\n",
    "shap.decision_plot(expected_value, shap_values, xtrain2.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(expected_value, shap_values[misclassified], features_display[misclassified],\n",
    "                link='logit', matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (shap_values.sum(1) + expected_value) > 0\n",
    "misclassified = y_pred != y_test[select]\n",
    "shap.decision_plot(expected_value, shap_values, features_display, link='logit', highlight=misclassified)\n",
    "# Our naive cutoff point is zero log odds (probability 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 FULL\n",
    "file_specific_pth = \"images/STAND/FULL/XGB/\"\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "train_x = pd.DataFrame(xtrain2)\n",
    "test_x = pd.DataFrame(xtest2)\n",
    "valid_x = pd.DataFrame(xvalid2)\n",
    "\n",
    "train_y = pd.DataFrame(y_train)\n",
    "test_y = pd.DataFrame(y_test)\n",
    "valid_y = pd.DataFrame(y_valid)\n",
    "\n",
    "x1 = train_x[(train_y == 1).values]\n",
    "y1 = train_y[(train_y == 1).values]\n",
    "\n",
    "x, y = resample(x1, y1,\n",
    "                replace = True,\n",
    "                n_samples = (len(train_y) - 2*sum(train_y)),\n",
    "                random_state = rand_state)\n",
    "\n",
    "xt = pd.concat([train_x, x])\n",
    "yt = pd.concat([train_y, y])\n",
    "\n",
    "xs, ys = shuffle(xt, yt, \n",
    "                 random_state = rand_state)\n",
    "\n",
    "xgb = XGBClassifier(learning_rate = 0.10, \n",
    "                min_split_loss = 0,\n",
    "                max_depth = 2,\n",
    "                gamma = 0.5,\n",
    "                min_child_weight = 1,\n",
    "                max_delta_step = 0,\n",
    "                subsample = 1,\n",
    "                n_estimators = 400)\n",
    "\n",
    "eval_set = [(train_x, train_y), (valid_x, valid_y)]\n",
    "\n",
    "xgb.fit(xs, ys, \n",
    "        eval_metric='auc', \n",
    "        eval_set = eval_set)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, train_x, test_x, valid_x, train_y, test_y, valid_y)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(xgb, test_x, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, xgb.predict(test_x))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = xgb.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 REDUC\n",
    "file_specific_pth = \"images/STAND/REDUC/XGB/\"\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "train_x = pd.DataFrame(x_train2[x_t2_lst])\n",
    "test_x = pd.DataFrame(x_test2[x_t2_lst])\n",
    "valid_x = pd.DataFrame(x_valid2[x_t2_lst])\n",
    "\n",
    "train_y = pd.DataFrame(y_train)\n",
    "test_y = pd.DataFrame(y_test)\n",
    "valid_y = pd.DataFrame(y_valid)\n",
    "\n",
    "x1 = train_x[(train_y == 1).values]\n",
    "y1 = train_y[(train_y == 1).values]\n",
    "\n",
    "x, y = resample(x1, y1,\n",
    "                replace = True,\n",
    "                n_samples = (len(train_y) - 2*sum(train_y)),\n",
    "                random_state = rand_state)\n",
    "\n",
    "xt = pd.concat([train_x, x])\n",
    "yt = pd.concat([train_y, y])\n",
    "\n",
    "xs, ys = shuffle(xt, yt, \n",
    "                 random_state = rand_state)\n",
    "\n",
    "xgb = XGBClassifier(learning_rate = 0.10, \n",
    "                min_split_loss = 0,\n",
    "                max_depth = 2,\n",
    "                gamma = 0.5,\n",
    "                min_child_weight = 1,\n",
    "                max_delta_step = 0,\n",
    "                subsample = 1,\n",
    "                n_estimators = 400)\n",
    "\n",
    "eval_set = [(train_x, train_y), (valid_x, valid_y)]\n",
    "\n",
    "xgb.fit(xs, ys, \n",
    "        eval_metric='auc', \n",
    "        eval_set = eval_set)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, train_x, test_x, valid_x, train_y, test_y, valid_y)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(xgb, test_x, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, xgb.predict(test_x))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = xgb.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRANS: xtrain3 FULL\n",
    "file_specific_pth = \"images/STAND_TRAN/FULL/XGB/\"\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "train_x = pd.DataFrame(xtrain3)\n",
    "test_x = pd.DataFrame(xtest3)\n",
    "valid_x = pd.DataFrame(xvalid3)\n",
    "\n",
    "train_y = pd.DataFrame(y_train)\n",
    "test_y = pd.DataFrame(y_test)\n",
    "valid_y = pd.DataFrame(y_valid)\n",
    "\n",
    "x1 = train_x[(train_y == 1).values]\n",
    "y1 = train_y[(train_y == 1).values]\n",
    "\n",
    "x, y = resample(x1, y1,\n",
    "                replace = True,\n",
    "                n_samples = (len(train_y) - 2*sum(train_y)),\n",
    "                random_state = rand_state)\n",
    "\n",
    "xt = pd.concat([train_x, x])\n",
    "yt = pd.concat([train_y, y])\n",
    "\n",
    "xs, ys = shuffle(xt, yt, \n",
    "                 random_state = rand_state)\n",
    "\n",
    "xgb = XGBClassifier(learning_rate = 0.10, \n",
    "                min_split_loss = 0,\n",
    "                max_depth = 2,\n",
    "                gamma = 0.5,\n",
    "                min_child_weight = 1,\n",
    "                max_delta_step = 0,\n",
    "                subsample = 1,\n",
    "                n_estimators = 400)\n",
    "\n",
    "eval_set = [(train_x, train_y), (valid_x, valid_y)]\n",
    "\n",
    "xgb.fit(xs, ys, \n",
    "        eval_metric='auc', \n",
    "        eval_set = eval_set)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, train_x, test_x, valid_x, train_y, test_y, valid_y)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(xgb, test_x, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, xgb.predict(test_x))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = xgb.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# shap.TreeExplainer\n",
    "\n",
    "# build a Permutation explainer and explain the model predictions on the given dataset\n",
    "# explainer = shap.explainers.GPUTree(xgb, xtrain3)\n",
    "# shap_values = explainer(xtrain3)\n",
    "\n",
    "# get just the explanations for the positive class\n",
    "# shap_values = shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRANS: xtrain3 REDUC\n",
    "file_specific_pth = \"images/STAND_TRAN/REDUC/XGB/\"\n",
    "\n",
    "best_train_auc = 0\n",
    "best_test_auc = 0\n",
    "best_valid_auc = 0\n",
    "\n",
    "best_train_accuracy = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "train_x = pd.DataFrame(x_train3[x_t3_lst])\n",
    "test_x = pd.DataFrame(x_test3[x_t3_lst])\n",
    "valid_x = pd.DataFrame(x_valid3[x_t3_lst])\n",
    "\n",
    "train_y = pd.DataFrame(y_train)\n",
    "test_y = pd.DataFrame(y_test)\n",
    "valid_y = pd.DataFrame(y_valid)\n",
    "\n",
    "x1 = train_x[(train_y == 1).values]\n",
    "y1 = train_y[(train_y == 1).values]\n",
    "\n",
    "x, y = resample(x1, y1,\n",
    "                replace = True,\n",
    "                n_samples = (len(train_y) - 2*sum(train_y)),\n",
    "                random_state = rand_state)\n",
    "\n",
    "xt = pd.concat([train_x, x])\n",
    "yt = pd.concat([train_y, y])\n",
    "\n",
    "xs, ys = shuffle(xt, yt, \n",
    "                 random_state = rand_state)\n",
    "\n",
    "xgb = XGBClassifier(learning_rate = 0.10, \n",
    "                min_split_loss = 0,\n",
    "                max_depth = 2,\n",
    "                gamma = 0.5,\n",
    "                min_child_weight = 1,\n",
    "                max_delta_step = 0,\n",
    "                subsample = 1,\n",
    "                n_estimators = 400)\n",
    "\n",
    "eval_set = [(train_x, train_y), (valid_x, valid_y)]\n",
    "\n",
    "xgb.fit(xs, ys, \n",
    "        eval_metric='auc', \n",
    "        eval_set = eval_set)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, train_x, test_x, valid_x, train_y, test_y, valid_y)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(xgb, test_x, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, xgb.predict(test_x))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = xgb.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'XGB_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD WORK\n",
    "\n",
    "\n",
    "# xgblst = []\n",
    "# xg_mod = []\n",
    "\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# lr = [0.01, 0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "# n_est = [10, 100, 200, 300, 400, 500]\n",
    "# depth = [3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# for learn in lr:\n",
    "#     for nest in n_est:\n",
    "#             for dep in depth:\n",
    "#                 params = [learn, nest, dep]\n",
    "#                 xgb = XGBClassifier(learning_rate = learn, \n",
    "#                                 min_split_loss = 0,\n",
    "#                                 max_depth = dep,\n",
    "#                                 min_child_weight = 1,\n",
    "#                                 max_delta_step = 0,\n",
    "#                                 subsample = 1,\n",
    "#                                 n_estimators = nest)\n",
    "                \n",
    "#                 eval_set = [(train_x, train_y), (valid_x, valid_y)]\n",
    "                \n",
    "#                 xgb.fit(xs, ys, \n",
    "#                         eval_metric='auc', \n",
    "#                         eval_set = eval_set)\n",
    "\n",
    "#                 train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, train_x, test_x, valid_x, train_y, test_y, valid_y)\n",
    "\n",
    "#                 outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                 if train_auc > best_train_auc:\n",
    "#                         best_train_auc = train_auc\n",
    "#                         b_tr_auc = outs\n",
    "#                 if test_auc > best_test_auc:\n",
    "#                         best_test_auc = test_auc\n",
    "#                         b_ts_auc = outs\n",
    "#                 if valid_auc > best_valid_auc:\n",
    "#                         best_valid_auc = valid_auc\n",
    "#                         b_v_auc = outs\n",
    "#                 if train_accuracy > best_train_accuracy:\n",
    "#                         best_train_accuracy = train_accuracy\n",
    "#                         b_tr_acc = outs\n",
    "#                 if test_accuracy > best_test_accuracy:\n",
    "#                         best_test_accuracy = test_accuracy\n",
    "#                         b_ts_acc = outs\n",
    "#                 if valid_accuracy > best_valid_accuracy:\n",
    "#                         best_valid_accuracy = valid_accuracy\n",
    "#                         b_v_acc = outs\n",
    "\n",
    "#                 xgblst.append([learn, nest, dep,\n",
    "#                         train_auc, test_auc, valid_auc,\n",
    "#                         train_accuracy, test_accuracy, valid_accuracy]) \n",
    "\n",
    "# colums = [\"learning_rate\", \"n_est\", \"dep\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# xgblst_outcomes = pd.DataFrame(xgblst, columns = colums)\n",
    "\n",
    "# print(\"Best Training Accuracy: \", best_train_accuracy, b_tr_auc)\n",
    "# print(\"Best     Test Accuracy: \", best_test_accuracy, b_ts_auc)\n",
    "# print(\"Best    Valid Accuracy: \", best_valid_accuracy, b_v_auc)\n",
    "\n",
    "# print(\"Best      Training AUC: \", best_train_auc, b_tr_acc)\n",
    "# print(\"Best          Test AUC: \", best_test_auc, b_ts_acc)\n",
    "# print(\"Best         Valid AUC: \", best_valid_auc, b_v_acc)\n",
    "\n",
    "# xgblst_outcomes.sort_values(\"Test_AUC\", ascending = False)\n",
    "# xgblst_outcomes[\"AUC_traintest_diff\"] = xgblst_outcomes[\"Test_AUC\"] - xgblst_outcomes[\"Train_AUC\"]\n",
    "# xgblst_outcomes[\"ABS_AUC_traintest_diff\"] = abs(xgblst_outcomes[\"Test_AUC\"] - xgblst_outcomes[\"Train_AUC\"])\n",
    "# xgblst_outcomes[\"max_acc_ratio\"] = round(((xgblst_outcomes[\"Test_Accurcy\"] / xgblst_outcomes[\"Test_Accurcy\"].max()) - 1) * 100, 2)\n",
    "\n",
    "# xgblst_outcomes.query(\"Train_AUC < Test_AUC\").sort_values(\"ABS_AUC_traintest_diff\", ascending=True).head(15)\n",
    "# xgblst_outcomes.sort_values(\"ABS_AUC_traintest_diff\", ascending=True).head(15)\n",
    "# logReg_outcomes.sort_values(\"Test_Accurcy\", ascending=False).head(5)\n",
    "\n",
    "# learning_rate\tn_est\tdep\tTrain_AUC\tTest_AUC\tValid_AUC\tTrain_Accurcy\tTest_Accurcy\tValid_Accurcy\tAUC_traintest_diff\tABS_AUC_traintest_diff\tmax_acc_ratio           \n",
    "# 0.30\t        10\t    4\t0.9819\t    0.9621\t    0.9652\t    0.9075\t        0.885\t        0.887\t        -0.0198\t            0.0198\t                -3.49           \n",
    "# 0.01\t        500\t    3\t0.9815\t    0.9667\t    0.9671\t    0.9028\t        0.885\t        0.877\t        -0.0148\t            0.0148\t                -3.49           \n",
    "# 0.10\t        10\t    3\t0.9584\t    0.9532  \t0.9522  \t0.8721\t        0.854       \t0.871   \t    -0.0052\t            0.0052               \t-6.87           \n",
    "# 0.01\t        100 \t3\t0.9591  \t0.9527\t    0.9519\t    0.8708      \t0.860\t        0.866       \t-0.0064\t            0.0064  \t            -6.22           \n",
    "# 0.01\t        10  \t3\t0.9293  \t0.9195  \t0.9261  \t0.8564      \t0.846\t        0.857       \t-0.0098\t            0.0098\t                -7.74    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_lst_pca = []\n",
    "\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# n_est = [100]\n",
    "# depth = [5, 7]\n",
    "# gams = [10]\n",
    "# lr = [0.001]\n",
    "# lef = [100]\n",
    "# alph = [0.2]\n",
    "# n_comp = np.array(range(1,xtrain3.shape[1]-1,2)) # [5, 7, 9] # \n",
    "\n",
    "# for nc in n_comp:\n",
    "#     for learn in lr:\n",
    "#         for nest in n_est:\n",
    "#                 for dep in depth:\n",
    "#                     for g in gams:\n",
    "#                         for l in lef:\n",
    "#                             for a in alph:\n",
    "#                                 params = [nc, learn, nest, dep, g, l, a]\n",
    "\n",
    "#                                 pca = PCA(n_components = nc)\n",
    "#                                 pca.fit(xtrain3)\n",
    "\n",
    "#                                 train_img = pd.DataFrame(pca.transform(xtrain3))\n",
    "#                                 test_img = pd.DataFrame(pca.transform(xtest3))\n",
    "#                                 valid_img = pd.DataFrame(pca.transform(xvalid3))\n",
    "\n",
    "#                                 x1 = train_img[(train_y == 1).values.reshape(-1,)]\n",
    "#                                 y1 = train_y[(train_y == 1).values.reshape(-1,)]\n",
    "\n",
    "#                                 x, y = resample(x1, y1,\n",
    "#                                                 replace = True,\n",
    "#                                                 n_samples = (len(train_y) - 2*sum(train_y)),\n",
    "#                                                 random_state = rand_state)\n",
    "\n",
    "#                                 xt = pd.concat([train_img, x])\n",
    "#                                 yt = pd.concat([train_y, y])\n",
    "\n",
    "#                                 xs, ys = shuffle(xt, yt, \n",
    "#                                                 random_state = rand_state)\n",
    "\n",
    "#                                 xgb = XGBClassifier(learning_rate = learn, \n",
    "#                                                     gamma = g, # range [0, INF] a higher value means more conservative alg\n",
    "#                                                     max_depth = dep, # range [0, INF] a higher value means less conservative alg\n",
    "#                                                     min_child_weight = l, # range [0, INF] a higher value means more conservative alg\n",
    "#                                                     n_estimators = nest,\n",
    "#                                                     alpha = a,\n",
    "#                                                     random_state = rand_state)\n",
    "                                \n",
    "#                                 eval_set = [(train_img, train_y), (valid_img, valid_y)]\n",
    "                                \n",
    "#                                 xgb.fit(xs, ys, \n",
    "#                                         eval_metric='auc', \n",
    "#                                         eval_set = eval_set)\n",
    "                                \n",
    "#                                 train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(xgb, xs, test_img, valid_img, ys, y_test, y_valid)\n",
    "\n",
    "#                                 outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                                 if train_auc > best_train_auc:\n",
    "#                                     best_train_auc = train_auc\n",
    "#                                     b_tr_auc = outs\n",
    "#                                 if test_auc > best_test_auc:\n",
    "#                                     best_test_auc = test_auc\n",
    "#                                     b_ts_auc = outs\n",
    "#                                 if valid_auc > best_valid_auc:\n",
    "#                                     best_valid_auc = valid_auc\n",
    "#                                     b_v_auc = outs\n",
    "\n",
    "#                                 if train_accuracy > best_train_accuracy:\n",
    "#                                     best_train_accuracy = train_accuracy\n",
    "#                                     b_tr_acc = outs\n",
    "#                                 if test_accuracy > best_test_accuracy:\n",
    "#                                     best_test_accuracy = test_accuracy\n",
    "#                                     b_ts_acc = outs\n",
    "#                                 if valid_accuracy > best_valid_accuracy:\n",
    "#                                     best_valid_accuracy = valid_accuracy\n",
    "#                                     b_v_acc = outs\n",
    "\n",
    "#                                 xgb_lst_pca.append([nc, learn, dep, g, nest, l, a,\n",
    "#                                                     train_auc, test_auc, valid_auc,\n",
    "#                                                     train_accuracy, test_accuracy, valid_accuracy]) \n",
    "\n",
    "# colums = [\"n_comp\", \"learning_rate\", \"max_depth\", \"gamma\", \"max_iter\", \"leaf\", \"alpha\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# xgb_pca_outcomes = pd.DataFrame(xgb_lst_pca, columns = colums)\n",
    "\n",
    "# colums = [\"n_comp\", \"learning_rate\", \"max_depth\", \"gamma\", \"max_iter\", \"leaf\", \"alpha\",\n",
    "#           \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\",\n",
    "#           \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\",\n",
    "#           ]\n",
    "# xgb_pca_outcomes = pd.DataFrame(xgb_lst_pca, columns = colums)\n",
    "\n",
    "# print(\"Best Training Accuracy: \", best_train_accuracy, b_tr_auc)\n",
    "# print(\"Best     Test Accuracy: \", best_test_accuracy, b_ts_auc)\n",
    "# print(\"Best    Valid Accuracy: \", best_valid_accuracy, b_v_auc)\n",
    "\n",
    "# print(\"Best      Training AUC: \", best_train_auc, b_tr_acc)\n",
    "# print(\"Best          Test AUC: \", best_test_auc, b_ts_acc)\n",
    "# print(\"Best         Valid AUC: \", best_valid_auc, b_v_acc)\n",
    "\n",
    "# xgb_pca_outcomes.sort_values(\"Test_AUC\", ascending = False)\n",
    "# xgb_pca_outcomes[\"AUC_traintest_diff\"] = xgb_pca_outcomes[\"Test_AUC\"] - xgb_pca_outcomes[\"Train_AUC\"]\n",
    "# xgb_pca_outcomes[\"ABS_AUC_traintest_diff\"] = abs(xgb_pca_outcomes[\"Test_AUC\"] - xgb_pca_outcomes[\"Train_AUC\"])\n",
    "# xgb_pca_outcomes[\"ABS_Accurcy_traintest_diff\"] = abs(xgb_pca_outcomes[\"Test_Accurcy\"] - xgb_pca_outcomes[\"Train_Accurcy\"])\n",
    "# xgb_pca_outcomes[\"max_acc_ratio%\"] = round(((xgb_pca_outcomes[\"Test_Accurcy\"] / xgb_pca_outcomes[\"Test_Accurcy\"].max()) - 1) * 100, 2)\n",
    "\n",
    "# xgb_pca_outcomes.sort_values(\"ABS_Accurcy_traintest_diff\", ascending=True).head(15)\n",
    "# xgb_pca_outcomes.query(\"Train_AUC < 1\").sort_values(\"ABS_AUC_traintest_diff\", ascending=True).head(15)\n",
    "# xgb_pca_outcomes.sort_values(\"Test_Accurcy\", ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC_lst = []\n",
    "\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# crit = [\"gini\", \"entropy\"]\n",
    "# depth = [10]\n",
    "# lef = np.array()\n",
    "# n_est = [1000]\n",
    "\n",
    "# for c in crit:\n",
    "#         for n in n_est:\n",
    "#                 for d in depth:\n",
    "#                         for l in lef:\n",
    "#                                 params = [c, n, d, l]\n",
    "#                                 Random_forest = RandomForestClassifier(n_estimators = n, #  The number of trees in the forest.\n",
    "#                                                                         criterion = c,\n",
    "#                                                                         max_depth = d,  \n",
    "#                                                                         min_samples_leaf = l,\n",
    "#                                                                         class_weight = 'balanced_subsample',\n",
    "#                                                                         random_state = rand_state)\n",
    "#                                 Random_forest.fit(xtrain, y_train)\n",
    "\n",
    "#                                 train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain, xtest, xvalid, y_train, y_test, y_valid)\n",
    "\n",
    "#                                 outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                                 if train_auc > best_train_auc:\n",
    "#                                         best_train_auc = train_auc\n",
    "#                                         b_tr_auc = outs\n",
    "#                                 if test_auc > best_test_auc:\n",
    "#                                         best_test_auc = test_auc\n",
    "#                                         b_ts_auc = outs\n",
    "#                                 if valid_auc > best_valid_auc:\n",
    "#                                         best_valid_auc = valid_auc\n",
    "#                                         b_v_auc = outs\n",
    "\n",
    "#                                 if train_accuracy > best_train_accuracy:\n",
    "#                                         best_train_accuracy = train_accuracy\n",
    "#                                         b_tr_acc = outs\n",
    "#                                 if test_accuracy > best_test_accuracy:\n",
    "#                                         best_test_accuracy = test_accuracy\n",
    "#                                         b_ts_acc = outs\n",
    "#                                 if valid_accuracy > best_valid_accuracy:\n",
    "#                                         best_valid_accuracy = valid_accuracy\n",
    "#                                         b_v_acc = outs\n",
    "\n",
    "#                                 RFC_lst.append([c, n, d, l,\n",
    "#                                                 train_auc, test_auc, valid_auc,\n",
    "#                                                 train_accuracy, test_accuracy, valid_accuracy]) \n",
    "\n",
    "# colums = [\"criterion\", \"n_est\", \"max_depth\", \"leaf\", \"Train_AUC\", \"Test_AUC\", \"Valid_AUC\", \"Train_Accurcy\", \"Test_Accurcy\", \"Valid_Accurcy\"]\n",
    "\n",
    "# rand_forest_outcomes = pd.DataFrame(RFC_lst, columns = colums)\n",
    "\n",
    "# rand_forest_outcomes[\"AUC_traintest_diff\"] = rand_forest_outcomes[\"Test_AUC\"] - rand_forest_outcomes[\"Train_AUC\"]\n",
    "# rand_forest_outcomes[\"ABS_AUC_traintest_diff\"] = abs(rand_forest_outcomes[\"Test_AUC\"] - rand_forest_outcomes[\"Train_AUC\"])\n",
    "# rand_forest_outcomes[\"max_acc_ratio\"] = round(((rand_forest_outcomes[\"Test_Accurcy\"] / rand_forest_outcomes[\"Test_Accurcy\"].max()) - 1) * 100, 2)\n",
    "\n",
    "# rand_forest_outcomes.query(\"AUC_traintest_diff > 0\").sort_values(\"ABS_AUC_traintest_diff\", ascending=True).head(15)\n",
    "# rand_forest_outcomes.sort_values(\"ABS_AUC_traintest_diff\", ascending=True).head(15)\n",
    "# # rand_forest_outcomes.sort_values(\"Test_Accurcy\", ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain FULL\n",
    "file_specific_pth = \"images/ORIG/FULL/RanFor/\"\n",
    "\n",
    "xtrain_var = xtrain\n",
    "xtest_var = xtest\n",
    "xvalid_var = xvalid\n",
    "\n",
    "Random_forest = RandomForestClassifier(n_estimators = 1000, #  The number of trees in the forest.\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_depth = 6,  \n",
    "                                       min_samples_leaf = 10,\n",
    "                                       class_weight = 'balanced_subsample',\n",
    "                                       random_state = rand_state)\n",
    "Random_forest.fit(xtrain_var, y_train)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain_var, xtest_var, xvalid_var, y_train, y_test, y_valid)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(Random_forest, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, Random_forest.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = Random_forest.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIG: xtrain REDUC\n",
    "file_specific_pth = \"images/ORIG/REDUC/RanFor/\"\n",
    "\n",
    "xtrain_var = xtrain[x_t1_lst]\n",
    "xtest_var = xtest[x_t1_lst]\n",
    "xvalid_var = xvalid[x_t1_lst]\n",
    "\n",
    "Random_forest = RandomForestClassifier(n_estimators = 1000, #  The number of trees in the forest.\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_depth = 6,  \n",
    "                                       min_samples_leaf = 10,\n",
    "                                       class_weight = 'balanced_subsample',\n",
    "                                       random_state = rand_state)\n",
    "Random_forest.fit(xtrain_var, y_train)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain_var, xtest_var, xvalid_var, y_train, y_test, y_valid)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(Random_forest, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, Random_forest.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = Random_forest.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 FULL\n",
    "file_specific_pth = \"images/STAND/FULL/RanFor/\"\n",
    "\n",
    "xtrain_var = xtrain2\n",
    "xtest_var = xtest2\n",
    "xvalid_var = xvalid2\n",
    "\n",
    "Random_forest = RandomForestClassifier(n_estimators = 1000, #  The number of trees in the forest.\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_depth = 6,  \n",
    "                                       min_samples_leaf = 10,\n",
    "                                       class_weight = 'balanced_subsample',\n",
    "                                       random_state = rand_state)\n",
    "Random_forest.fit(xtrain_var, y_train)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain_var, xtest_var, xvalid_var, y_train, y_test, y_valid)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(Random_forest, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, Random_forest.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = Random_forest.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND: xtrain2 REDUC\n",
    "file_specific_pth = \"images/STAND/REDUC/RanFor/\"\n",
    "\n",
    "xtrain_var = xtrain2[x_t2_lst]\n",
    "xtest_var = xtest2[x_t2_lst]\n",
    "xvalid_var = xvalid2[x_t2_lst]\n",
    "\n",
    "Random_forest = RandomForestClassifier(n_estimators = 1000, #  The number of trees in the forest.\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_depth = 6,  \n",
    "                                       min_samples_leaf = 10,\n",
    "                                       class_weight = 'balanced_subsample',\n",
    "                                       random_state = rand_state)\n",
    "Random_forest.fit(xtrain_var, y_train)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain_var, xtest_var, xvalid_var, y_train, y_test, y_valid)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(Random_forest, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, Random_forest.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = Random_forest.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRANS: xtrain3 FULL\n",
    "file_specific_pth = \"images/STAND_TRAN/FULL/RanFor/\"\n",
    "\n",
    "xtrain_var = xtrain3\n",
    "xtest_var = xtest3\n",
    "xvalid_var = xvalid3\n",
    "\n",
    "Random_forest = RandomForestClassifier(n_estimators = 1000, #  The number of trees in the forest.\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_depth = 6,  \n",
    "                                       min_samples_leaf = 10,\n",
    "                                       class_weight = 'balanced_subsample',\n",
    "                                       random_state = rand_state)\n",
    "Random_forest.fit(xtrain_var, y_train)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain_var, xtest_var, xvalid_var, y_train, y_test, y_valid)\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(Random_forest, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, Random_forest.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = Random_forest.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ConfuMatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAND_TRANS: xtrain3 REDUC\n",
    "file_specific_pth = \"images/STAND_TRAN/REDUC/RanFor/\"\n",
    "\n",
    "xtrain_var = xtrain3[x_t3_lst]\n",
    "xtest_var = xtest3[x_t3_lst]\n",
    "xvalid_var = xvalid3[x_t3_lst]\n",
    "\n",
    "Random_forest = RandomForestClassifier(n_estimators = 1000, #  The number of trees in the forest.\n",
    "                                       criterion = \"gini\",\n",
    "                                       max_depth = 6,  \n",
    "                                       min_samples_leaf = 10,\n",
    "                                       class_weight = 'balanced_subsample',\n",
    "                                       random_state = rand_state)\n",
    "Random_forest.fit(xtrain_var, y_train)\n",
    "\n",
    "train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, xtrain_var, xtest_var, xvalid_var, y_train, y_test, y_valid)\n",
    "\n",
    "outs = [train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "if train_auc > best_train_auc:\n",
    "        best_train_auc = train_auc\n",
    "if test_auc > best_test_auc:\n",
    "        best_test_auc = test_auc\n",
    "if valid_auc > best_valid_auc:\n",
    "        best_valid_auc = valid_auc\n",
    "if train_accuracy > best_train_accuracy:\n",
    "        best_train_accuracy = train_accuracy\n",
    "if test_accuracy > best_test_accuracy:\n",
    "        best_test_accuracy = test_accuracy\n",
    "if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "\n",
    "print(\"Best Training Accuracy: \", best_train_accuracy)\n",
    "print(\"Best     Test Accuracy: \", best_test_accuracy)\n",
    "print(\"Best    Valid Accuracy: \", best_valid_accuracy)\n",
    "\n",
    "print(\"Best      Training AUC: \", best_train_auc)\n",
    "print(\"Best          Test AUC: \", best_test_auc)\n",
    "print(\"Best         Valid AUC: \", best_valid_auc)\n",
    "\n",
    "metrics.plot_roc_curve(Random_forest, xtest_var, y_test)\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ROC.png')\n",
    "\n",
    "cm = confusion_matrix(y_test, Random_forest.predict(xtest_var))\n",
    "ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = Random_forest.classes_).plot()\n",
    "plt.savefig(my_filesys_pth + file_specific_pth + 'RF_ConfuMatrix.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFC_lst = []\n",
    "\n",
    "# best_train_auc = 0\n",
    "# best_test_auc = 0\n",
    "# best_valid_auc = 0\n",
    "\n",
    "# best_train_accuracy = 0\n",
    "# best_test_accuracy = 0\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# crit = [\"gini\", \"entropy\"]\n",
    "# depth = [10]\n",
    "# lef = [1,2,3,4,5,6,7,8,9,10,20,50,100]\n",
    "# n_est = [1000]\n",
    "\n",
    "# for nc in n_comp:\n",
    "#         for c in crit:\n",
    "#                 for n in n_est:\n",
    "#                         for d in depth:\n",
    "#                                 for l in lef:\n",
    "#                                         params = [nc, c, n, d, l]\n",
    "\n",
    "#                                         pca = PCA(n_components = nc)\n",
    "#                                         pca.fit(xtrain2)\n",
    "\n",
    "#                                         train_img = pca.transform(xtrain2)\n",
    "#                                         test_img = pca.transform(xtest2)\n",
    "#                                         valid_img = pca.transform(xvalid2)\n",
    "\n",
    "#                                         Random_forest = RandomForestClassifier(n_estimators = n, #  The number of trees in the forest.\n",
    "#                                                                                 criterion = c,\n",
    "#                                                                                 max_depth = d,  \n",
    "#                                                                                 min_samples_leaf = l,\n",
    "#                                                                                 class_weight = 'balanced_subsample',\n",
    "#                                                                                 random_state = rand_state)\n",
    "#                                         Random_forest.fit(xtrain, y_train)\n",
    "\n",
    "#                                         train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy = get_outs(Random_forest, train_img, test_img, valid_img, y_train, y_test, y_valid)\n",
    "\n",
    "#                                         outs = [params, train_auc, test_auc, valid_auc, train_accuracy, test_accuracy, valid_accuracy]\n",
    "\n",
    "#                                         if train_auc > best_train_auc:\n",
    "#                                                 best_train_auc = train_auc\n",
    "#                                                 b_tr_auc = outs\n",
    "#                                         if test_auc > best_test_auc:\n",
    "#                                                 best_test_auc = test_auc\n",
    "#                                                 b_ts_auc = outs\n",
    "#                                         if valid_auc > best_valid_auc:\n",
    "#                                                 best_valid_auc = valid_auc\n",
    "#                                                 b_v_auc = outs\n",
    "\n",
    "#                                         if train_accuracy > best_train_accuracy:\n",
    "#                                                 best_train_accuracy = train_accuracy\n",
    "#                                                 b_tr_acc = outs\n",
    "#                                         if test_accuracy > best_test_accuracy:\n",
    "#                                                 best_test_accuracy = test_accuracy\n",
    "#                                                 b_ts_acc = outs\n",
    "#                                         if valid_accuracy > best_valid_accuracy:\n",
    "#                                                 best_valid_accuracy = valid_accuracy\n",
    "#                                                 b_v_acc = outs\n",
    "\n",
    "#                                         RFC_lst.append([nc, c, n, d, l,\n",
    "#                                                         train_auc, test_auc, valid_auc,\n",
    "#                                                         train_accuracy, test_accuracy, valid_accuracy]) \n",
    "\n",
    "# rand_forest_outcomes = pd.DataFrame(RFC_lst, columns = [\"n_comp\", \"criterion\", \"n_est\", \"max_depth\", \"leaf\", \"Train_AUC\", \"Train_Accurcy\", \"Test_AUC\", \"Test_Accurcy\", \"Valid_AUC\", \"Valid_Accurcy\"])\n",
    "# rand_forest_outcomes\n",
    "\n",
    "# n_comp\tcriterion\tn_est\tmax_depth\tleaf\tTrain_AUC\tTest_AUC\tValid_AUC\tTrain_Accurcy\tTest_Accurcy\tValid_Accurcy\tAUC_traintest_diff\tABS_AUC_traintest_diff\tmax_acc_ratio\ttesttrain_acc_ratio\n",
    "# 39\t3\tgini\t1000\t6\t20\t0.8700\t0.8588\t0.8568\t0.7783\t0.779\t0.776\t-0.0112\t0.0112\t7.1514\t1.0009\n",
    "# 34\t3\tgini\t1000\t3\t15\t0.8283\t0.8338\t0.8277\t0.7517\t0.759\t0.750\t0.0055\t0.0055\t9.5352\t1.0097\n",
    "# 35\t3\tgini\t1000\t3\t20\t0.8281\t0.8334\t0.8273\t0.7520\t0.759\t0.750\t0.0053\t0.0053\t9.5352\t1.0093\n",
    "# 48\t3\tentropy\t1000\t3\t5\t0.8291\t0.8349\t0.8295\t0.7530\t0.759\t0.750\t0.0058\t0.0058\t9.5352\t1.0080\n",
    "# 32\t3\tgini\t1000\t3\t5\t0.8284\t0.8346\t0.8276\t0.7533\t0.758\t0.750\t0.0062\t0.0062\t9.6544\t1.0062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "591957650fd2dfa38b1c766d9610be12ab5ecbc623c9062aec785c096eff7328"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
